{"ast":null,"code":"import React,{useState}from'react';import{BarChart,Bar,XAxis,YAxis,CartesianGrid,Tooltip,Legend,ResponsiveContainer,RadarChart,PolarGrid,PolarAngleAxis,PolarRadiusAxis,Radar}from'recharts';import{Info,CheckCircle,AlertTriangle,XCircle,HelpCircle,ChevronDown,BarChart3,FileText}from'lucide-react';import{jsx as _jsx,jsxs as _jsxs,Fragment as _Fragment}from\"react/jsx-runtime\";const AI_MODULES={MAPPING:'ai-mapping',REGULATION:'ai-regulation',RESPONSIBLE_AI:'responsible-ai',RISK:'ai-risk'};const AI_MODULES_INFO={[AI_MODULES.MAPPING]:{title:'AI Model Mapping',description:'Match machine learning models to application needs based on data modality, task type, learning paradigm, and constraints.',guideTitle:'AI Model Mapping Guide',questTitle:'ML Model Selection Questionnaire'},[AI_MODULES.REGULATION]:{title:'AI Regulation & Policy',description:'Ensure compliance with federal AI regulations and policies for responsible and transparent AI governance.',guideTitle:'Federal AI Regulations Guide',questTitle:'Federal AI Compliance Questionnaire'},[AI_MODULES.RESPONSIBLE_AI]:{title:'Responsible AI',description:'Apply the five core principles of Responsible AI: Bias & Fairness, Privacy & Security, Transparency, Accountability, and Robustness.',guideTitle:'Responsible AI Principles Guide',questTitle:'Responsible AI Compliance Questionnaire'},[AI_MODULES.RISK]:{title:'AI Risk Management',description:'Identify, evaluate, respond to, and govern AI risks through the NIST AI Risk Management Framework.',guideTitle:'NIST AI RMF Guide',questTitle:'AI RMF Risk Assessment Questionnaire'}};// Information guides content\nconst GUIDE_CONTENT={[AI_MODULES.MAPPING]:[{title:'Data Modality',items:['Tabular data: Structured data in tables with rows and columns. This includes CSV files, database tables, and spreadsheets. Common in business applications, financial systems, and enterprise environments where data is highly structured and follows a schema.','Text data: Unstructured or semi-structured data such as articles, documents, reviews, emails, and chat logs. These require natural language processing techniques and typically benefit from transformer-based models that can understand semantic meaning.','Image data: Pixel-based data including grayscale and RGB images, medical scans, satellite imagery, and video frames. Convolutional neural networks excel with these inputs by detecting spatial patterns and hierarchical features.','Time series data: Sequential data points collected over time, such as sensor readings, stock prices, IoT device metrics, and user activity logs. Temporal patterns and seasonality are key features that specialized algorithms can detect.']},{title:'Machine Learning Task',items:['Classification: Assigning data to predefined categories or classes. Examples include spam detection, sentiment analysis, disease diagnosis, and object recognition. Classification models output discrete labels or probabilities of class membership, with metrics like accuracy, precision, recall, and F1 score used for evaluation.','Regression: Predicting continuous numerical values based on input features. Use cases include price prediction, demand forecasting, and resource allocation. These models output real numbers rather than categories, with performance measured by metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.','Clustering: Grouping similar data points together without predefined labels. Used for customer segmentation, anomaly detection, and document organization. Algorithms like K-means, DBSCAN, and hierarchical clustering identify natural groupings in data based on similarity or distance measures.','Anomaly Detection: Identifying rare, unusual, or suspicious data instances that deviate significantly from the norm. Critical for fraud detection, network security, manufacturing quality control, and system health monitoring. These models learn what \"normal\" patterns look like and flag deviations.']},{title:'Learning Paradigm',items:['Supervised learning: Learning from labeled data with known outcomes. The model is trained on input-output pairs (features and target labels/values) and learns to predict outputs for new inputs. This is the most common approach, suitable when you have sufficient labeled data and clear target variables. Examples include image classification, sentiment analysis, and spam filtering.','Unsupervised learning: Learning patterns and structures from unlabeled data without explicit guidance. The algorithm discovers hidden patterns, groupings, or representations in data. Used when labeled data is unavailable or expensive to obtain, or when exploring unknown patterns. Examples include clustering, dimensionality reduction, and anomaly detection.','Semi-supervised learning: Learning from a mix of labeled and unlabeled data. This hybrid approach leverages small amounts of labeled data with larger amounts of unlabeled data. Particularly valuable when obtaining labeled data is expensive or time-consuming. Common in medical imaging, speech recognition, and text classification where partial labeling is feasible.','Reinforcement learning: Learning optimal actions through trial-and-error interactions with an environment. The model (agent) learns by receiving rewards or penalties based on its actions. Used for sequential decision-making problems like robotics, game playing, autonomous vehicles, and resource management. Differs from other paradigms by focusing on long-term rewards rather than immediate prediction accuracy.']},{title:'Constraints',items:['Model complexity: The sophistication of the model and interpretability trade-offs. Simpler models (linear regression, decision trees) are more explainable but may underfit complex data. Complex models (deep neural networks, ensemble methods) can capture intricate patterns but function as \"black boxes,\" creating challenges for explainability, regulatory compliance, and stakeholder trust. Consider your explainability requirements carefully when selecting model architecture.','Training resources: Amount of computational power, memory, time, and expertise needed. Resource requirements increase with data size, model complexity, and hyperparameter tuning needs. Consider your available infrastructure (CPUs, GPUs, TPUs, cloud resources), time constraints, and budget. Remember that resource-intensive models also typically require specialized expertise to develop and maintain.','Inference speed: How quickly the model can make predictions after deployment. Critical for real-time applications like autonomous vehicles, fraud detection, and recommendation systems. Models with fast inference may require optimization techniques like quantization, pruning, distillation, or specialized hardware. Consider latency requirements, throughput needs, and deployment environment constraints (edge devices, browser-based, server-side).','Operational considerations: Additional factors like model maintainability, retraining frequency, data pipeline complexity, and integration with existing systems. Consider the full lifecycle of your model, including monitoring for drift, versioning, A/B testing capabilities, and compliance with organizational policies and industry regulations.']}],[AI_MODULES.REGULATION]:[{title:'Identification & Governance',items:['System Inventory: AI systems must be cataloged in the agency\\'s use case inventory. This inventory should include comprehensive metadata about each AI system, including purpose, data sources, development methodology, deployment status, and risk classification. Regular audits should ensure the inventory remains current as systems evolve or new ones are developed.','Designated Leadership: Each agency must have a Chief AI Officer and governance lead who is accountable for AI risk management and compliance. This leadership role should have sufficient authority, resources, and expertise to effectively oversee AI activities across the organization. The CAIO typically reports to senior leadership and coordinates with privacy, security, and ethics officers.','Review by AI Board: Governance boards should evaluate rights-impacting or high-risk systems through a structured review process. These cross-functional boards typically include legal, technical, ethics, and domain experts who conduct thorough assessments before deployment and during operation. High-risk systems require more rigorous review, including potential red-team exercises and independent verification.']},{title:'Purpose & Use Justification',items:['Mission Alignment: AI use must support federal missions and not contradict statutory limits. Agencies should clearly document how each AI system furthers specific mission objectives and operates within legal boundaries. This requires collaboration between technical teams, legal counsel, and policy experts to ensure both technical capabilities and implementation approaches align with the agency\\'s authorized activities and avoid mission creep or statutory violations.','Rights-Impacting Assessment: Evaluate if the AI system affects individual rights or access to benefits. Systems that influence decisions about individuals—especially in areas like benefits determination, law enforcement, immigration, or public services—require heightened scrutiny. This assessment should analyze potential impacts on constitutional rights, civil liberties, privacy, and equitable access to government services, with special attention to effects on marginalized communities.','Public Disclosure: Purpose and function must be stated in clear, accessible language. Agencies must provide transparency about AI systems through public-facing documentation that avoids technical jargon. This disclosure should include the system\\'s purpose, capabilities, limitations, data sources (at an appropriate level of detail), and how it fits into agency decision-making processes. For sensitive systems, disclosures should provide meaningful transparency while respecting security and privacy constraints.']},{title:'Risk Assessment & Classification',items:['Risk-Based Impact Assessment (RBIA): Conducted to classify systems as low, moderate, or high impact. This formal assessment evaluates potential harms across multiple dimensions including rights and safety impacts, scope of deployment, autonomy level, and technical maturity. The resulting classification determines the governance requirements, with high-impact systems subject to more stringent controls. RBIA should consider both likelihood and severity of potential harms, with special attention to irreversible impacts.','Independent Evaluation: External reviews or red-teaming are encouraged for high-risk systems. Third-party assessments provide valuable independent verification of risk controls and can identify blind spots missed by internal teams. For high-impact systems, these evaluations should include adversarial testing, stress testing with edge cases, and evaluation of fairness across demographic groups. Independent reviewers should have appropriate expertise and sufficient access to system details.','Ongoing Monitoring: Risks should be evaluated before and after deployment, with regular reassessments throughout the system lifecycle. Initial risk assessments are insufficient; agencies must implement continuous monitoring to detect emergent risks, performance degradation, or concept drift. This includes establishing key risk indicators, threshold alerts, regular risk reviews, and post-incident analyses to ensure risks remain within acceptable tolerances and to identify new mitigation strategies as the operational environment evolves.']},{title:'Transparency & Explainability',items:['Documentation: Models and datasets must be documented and version-controlled. This documentation should include model architecture, training methodology, performance metrics, testing procedures, known limitations, data sources, and preprocessing steps. Model cards and datasheets are emerging standards that provide structured templates for thorough documentation. Version control should track all changes to models and data, including retraining cycles, with the ability to roll back to previous versions if issues arise.','Explainability: AI outputs should be understandable to users, especially for critical decisions. Agencies must provide appropriate explanations tailored to different stakeholder needs—from technical details for specialists to clear reasoning for affected individuals. Explainability approaches should be proportional to the system\\'s impact and complexity. For high-impact systems, agencies should implement layered explanations that provide both overview-level and detailed justifications for outcomes.','Interpretability Tools: Use SHAP, LIME, or similar techniques to explain high-stakes predictions. For complex models like neural networks, these interpretability methods help identify which features most influence specific predictions. Tools should be selected based on the model type, use case, and stakeholder needs. For critical systems, agencies should implement multiple complementary interpretability approaches, as each method has different strengths and limitations. These tools should be incorporated into user interfaces where appropriate to provide real-time explanations.']},{title:'Human Oversight & Accountability',items:['Human-in-the-Loop: Ensure human review of key AI-driven decisions.','Redress Mechanisms: Establish paths for affected individuals to challenge outcomes.','Personnel Training: Operators must be trained in ethical AI use and escalation protocols.']},{title:'Privacy, Fairness & Data Integrity',items:['SAOP Involvement: The Senior Agency Official for Privacy must assess the system.','Bias Audits: Fairness audits should assess disparate impact and demographic performance.','Data Governance: Demographic and sensitive data use must be justified and documented.']},{title:'Security & Robustness',items:['ATO Compliance: Systems must comply with FISMA and receive Authority to Operate.','Security Controls: Safeguards against adversarial attacks and data leakage must be in place.','Performance Drift: Detect and mitigate performance decay and concept drift.']},{title:'Public Services & High-Impact Systems',items:['High-Impact Services: Systems affecting public service delivery must meet additional standards.','Public Redress: Feedback and correction mechanisms should be made available.','IQA Compliance: Systems must meet Information Quality Act requirements.']},{title:'Lifecycle & Open Source Considerations',items:['Documentation Maintenance: Training, testing, and deployment documents must be up to date.','Decommissioning Plans: There should be a plan for system retirement or replacement.','Open Source Evaluation: Source code should be published when feasible and not restricted.']}],[AI_MODULES.RESPONSIBLE_AI]:[{title:'Bias & Fairness',items:['Dataset Representativeness: Ensure datasets reflect diverse populations and use disaggregated metrics. This requires careful data collection and curation to include adequate representation across relevant demographic groups. Organizations should document dataset composition, identify potential gaps or underrepresented groups, and supplement data where necessary. Disaggregated metrics involve analyzing model performance separately for different subgroups to identify disparities that might be hidden in aggregate statistics.','Bias Audits: Perform fairness audits using metrics like disparate impact or equal opportunity. Fairness audits should be conducted throughout the AI lifecycle—during development, before deployment, and regularly in production. Organizations should select appropriate fairness metrics based on the specific context and use case. Common metrics include demographic parity, equal opportunity, equalized odds, and counterfactual fairness. The results of these audits should inform model modifications and deployment decisions.','Fairness Constraints: Apply fairness-aware methods during training and evaluation. These methods can include pre-processing techniques (modifying training data to reduce bias), in-processing approaches (incorporating fairness objectives directly into model training), and post-processing methods (adjusting model outputs to ensure fair results). Organizations should document which fairness definitions and constraints they prioritize, as different fairness metrics can sometimes be mathematically incompatible.','Disparate Impact Monitoring: Evaluate model behavior across subgroups to identify differential performance. This involves regular testing across demographic categories and protected attributes to uncover unintended discrimination. Organizations should establish thresholds for acceptable performance differences and implement alerting systems when disparities exceed these thresholds. For high-risk applications, consider using formal disparate impact analysis frameworks from legal and regulatory contexts.','Unfair Outcome Mitigation: Establish procedures to detect and resolve inequitable results. Create clear protocols for addressing fairness issues when discovered, including potential model updates, additional controls, or human review processes. Define escalation paths and response timelines based on the severity of fairness concerns. Mitigation strategies should be documented and evaluated for effectiveness. Organizations should maintain a library of fairness issues and their resolutions to build institutional knowledge.']},{title:'Privacy & Security',items:['Sensitive Data Protection: Ensure compliance with privacy regulations and minimize sensitive data use. Organizations should inventory all data used in AI systems, classify data sensitivity levels, and implement appropriate controls based on data type. This includes meeting requirements from regulations like GDPR, HIPAA, CCPA, and federal privacy laws. Sensitive data minimization principles should apply throughout the AI lifecycle—from collection to processing, storage, and retention. Organizations should document data flows and implement privacy impact assessments for high-risk systems.','Privacy-Enhancing Technologies (PETs): Use techniques like anonymization, differential privacy, or secure multiparty computation to protect individual privacy while maintaining utility. These technologies allow organizations to derive insights from sensitive data while minimizing privacy risks. Differential privacy adds mathematical noise to protect individual records while preserving statistical validity. Federated learning enables model training across distributed datasets without centralizing sensitive data. Homomorphic encryption allows computation on encrypted data without decryption.','Access Controls: Restrict access to models and outputs to authorized individuals based on least privilege principles. Implement role-based access controls, authentication mechanisms, and audit logging for all system interactions. For sensitive AI systems, consider implementing multi-factor authentication and privileged access management. Access permissions should be regularly reviewed and updated as roles change. AI outputs containing sensitive information should inherit the protection level of the underlying data.','Adversarial Defense: Protect against model manipulation, data poisoning, and inference attacks. Organizations should implement defenses against various attack vectors, including adversarial examples (inputs designed to cause misclassification), model inversion (reconstructing training data), and membership inference (determining if data was used in training). Defense strategies include adversarial training, input validation, model distillation, and regularization techniques that enhance model robustness.','External Audits: Conduct third-party reviews and penetration testing to identify vulnerabilities. Independent security assessments provide objective evaluation of security controls and identify gaps that internal teams might miss. For high-risk systems, organizations should implement a regular cadence of security audits, including penetration testing, model security reviews, and privacy assessments. Results should inform security improvements and be incorporated into organizational risk management processes.']},{title:'Transparency & Explainability',items:['Model Documentation: Provide detailed records of model architecture, training, and assumptions.','User-Facing Explanations: Offer explanations tailored to different stakeholder groups.','Interpretability Tools: Incorporate SHAP, LIME, or counterfactuals for complex models.','Non-Technical Communication: Use accessible language for public understanding.','Lifecycle Transparency: Keep documentation up to date through development and deployment.']},{title:'Accountability',items:['Ownership: Assign responsibility for AI system development, performance, and oversight.','Appeal Mechanisms: Allow users to contest or appeal AI-generated decisions.','Audit Trails: Log model outputs, training changes, and deployment events.','Governance Processes: Ensure models are reviewed by internal or external ethics boards.','Public Disclosure: Publish contact, policy, and impact information for accountability.']},{title:'Robustness & Reliability',items:['Stress Testing: Evaluate performance under edge cases and simulated attacks.','Monitoring & Maintenance: Track drift and accuracy over time and retrain as needed.','Fallback Strategies: Plan for system failure modes with safe alternatives.','Environment Testing: Validate behavior in varied and real-world contexts.','Operational Readiness: Confirm model stability prior to deployment.']}],[AI_MODULES.RISK]:[{title:'Map - Contextualization',items:['Purpose Clarity: Define the AI system\\'s function, role, and objectives with precision and specificity. This goes beyond simple descriptions to articulate exactly what the system is designed to do, its capabilities and limitations, and how it will be used in practice. The purpose statement should address the problem being solved, value proposition, intended users, and societal implications. This clarity is foundational for all subsequent risk assessment activities.','Stakeholder Identification: Engage developers, users, and impacted communities throughout the AI lifecycle. Stakeholder mapping should identify both direct stakeholders (users, operators, decision-makers) and indirect stakeholders (communities affected by decisions, marginalized groups, regulatory bodies). Engagement should be proportional to risk level and include diverse perspectives. For high-impact systems, consider creating formal advisory panels with representatives from affected communities.','Impact Mapping: Assess intended and unintended effects across the AI lifecycle using structured methodologies. This includes identifying primary, secondary, and tertiary impacts across social, economic, environmental, and ethical dimensions. Organizations should use techniques like scenario planning and consequence scanning to anticipate unexpected outcomes. Impact assessment should span from development through deployment, ongoing operation, and eventual decommissioning or replacement.','Legal/Ethical Fit: Confirm alignment with agency mission, legal boundaries, and ethical frameworks. This involves detailed analysis of relevant laws, regulations, ethical guidelines, and organizational values. For each identified risk, map applicable legal requirements and ethical principles. Document where compliance is required versus where ethical considerations go beyond legal minimums. This analysis should inform go/no-go decisions for AI development and deployment.','System Interactions: Document all system dependencies, integrations, and environmental interactions. Create comprehensive maps of how the AI system connects with other systems, data sources, and human workflows. This includes technical dependencies, operational relationships, and potential cascade effects. Understanding these interconnections is crucial for identifying emergent risks that arise from system interactions rather than from individual components.']},{title:'Measure - Risk Identification & Evaluation',items:['Risk Discovery Methods: Use scenario planning, testing, and expert input to systematically identify potential risks. Effective risk discovery employs multiple complementary methods, including red team exercises, tabletop scenarios, failure mode analysis, and expert workshops. Organizations should consider both known risks from similar systems and novel risks specific to the application context. For high-impact systems, implement participatory approaches that include diverse stakeholders in the risk identification process.','Severity and Likelihood Assessment: Estimate consequences and probability of risk events using both quantitative and qualitative methods. Develop impact scales that consider dimensions such as harm severity, number of people affected, duration of impact, and reversibility. Create likelihood scales based on historical data where available and structured expert judgment where needed. Risk prioritization should consider both dimensions, with special attention to low-probability, high-consequence events that could cause catastrophic harm.','Conditional Performance Evaluation: Assess accuracy under varied inputs and conditions to understand performance boundaries. Test model behavior across different subpopulations, edge cases, and adversarial scenarios. Identify conditions where performance degrades significantly, which represents hidden risk. For safety-critical applications, stress testing should evaluate performance under low-frequency but high-risk scenarios, including rare input patterns and system failures.','Comprehensive Metrics: Include fairness, robustness, privacy, and reliability measures beyond standard accuracy metrics. Develop a balanced scorecard of metrics relevant to the specific application context and stakeholder concerns. For each metric, establish thresholds that define acceptable performance levels and trigger points for intervention. Monitor trade-offs between competing objectives, such as privacy versus utility or performance versus explainability.','Risk Tracking: Maintain and update a comprehensive risk inventory throughout the AI lifecycle. The risk register should document each identified risk, its assessment, mitigations, ownership, and current status. Implement regular review cycles to update risk assessments as the system, its usage, or operating environment evolves. For high-impact systems, integrate AI risk tracking with enterprise risk management processes for appropriate governance oversight.']},{title:'Manage - Risk Response',items:['Mitigation Planning: Document controls and mitigation actions for each identified risk. Develop a structured response strategy that may include risk acceptance (for low-impact risks within tolerance), avoidance (eliminating the risk source), transfer (sharing risk through insurance or partnerships), or reduction (implementing controls to lower probability or impact). For each mitigation, document implementation approach, required resources, timeline, and expected risk reduction. Mitigation plans should be proportional to risk level and address root causes where possible.','Responsibility Assignment: Identify risk owners and maintain clear accountability throughout the AI lifecycle. Each identified risk should have a designated owner with appropriate authority and resources to implement mitigations. Responsibilities should span technical teams, business units, legal/compliance, and executive leadership based on risk nature and severity. Document roles in risk governance, including who approves risk acceptance decisions at different thresholds and who is responsible for ongoing monitoring and escalation.','Dynamic Risk Register: Keep risk logs updated and accessible to support active risk management. The risk register should be a living document that evolves as risks change, new risks emerge, and mitigations are implemented. Include risk descriptions, assessments, controls, status, review dates, and audit trail of changes. For complex or high-impact systems, consider implementing specialized AI risk management tools that can track risks across multiple dimensions and link to related artifacts.','Incident Escalation: Set clear thresholds and response protocols for emergent risks and incidents. Define triggers for different escalation levels based on impact severity, vulnerability exploitation, or performance degradation. Document notification requirements, response team composition, and decision authority at each escalation level. For high-impact systems, conduct regular incident response exercises to test protocols and improve organizational readiness.','Effectiveness Testing: Test risk mitigations for performance to verify they function as intended. Implement both pre-deployment validation and post-implementation monitoring of control effectiveness. For critical controls, conduct periodic testing under realistic conditions, including potential circumvention attempts. When mitigations prove less effective than expected, adjust the approach and document lessons learned to improve future risk management practices.']},{title:'Govern - Oversight & Accountability',items:['Governance Structure: Create oversight boards or designate responsible parties with clear authority and reporting lines. Effective AI governance requires formal structures with appropriate expertise, diversity, and decision-making authority. For organizations developing or deploying multiple AI systems, consider tiered governance with system-specific reviews feeding into enterprise-level oversight. Governance bodies should include technical expertise, domain knowledge, ethics perspectives, and legal/compliance representation to ensure comprehensive risk management.','Policy Integration: Align AI use with broader organizational policies on data governance, security, privacy, and ethics. AI governance should not exist in isolation but should connect to existing organizational frameworks. Document how AI-specific policies interact with enterprise risk management, information security, privacy, procurement, and compliance policies. This integration ensures consistency in risk approach and leverages existing controls where appropriate.','Audit Mechanisms: Use audit trails and logs for accountability throughout the AI lifecycle. Implement technical logging to capture key model behaviors, data access, and system changes. Document decision points, approvals, and policy exceptions. For high-impact systems, consider implementing immutable audit trails to prevent tampering. Automated monitoring and alerting should complement human review processes to flag anomalies or policy violations.','Ethical & Legal Oversight: Ensure adherence to AI governance frameworks, ethical guidelines, and legal mandates. Develop processes to monitor evolving regulations and standards in AI governance. Conduct regular compliance assessments against applicable laws, regulations, and ethical frameworks. Document how system design and operational controls address specific requirements, and maintain evidence of compliance for potential regulatory review.','Transparency Practices: Share relevant risk insights with internal and external stakeholders through appropriate channels. Determine what information should be shared with different stakeholder groups—from technical details for regulators to accessible summaries for affected communities. For public-facing systems, publish appropriate documentation about system purpose, capabilities, limitations, and governance. For internal systems, ensure decision-makers understand key risk factors and controls.']}]};// Sample questionnaires for each module\nconst QUESTIONNAIRES={[AI_MODULES.MAPPING]:[{question:\"What type of data will your AI system primarily process?\",options:[\"Tabular data\",\"Text data\",\"Image data\",\"Time series data\",\"Audio data\",\"Mixed data types\"],category:\"Data Modality\"},{question:\"What is the primary task your AI system needs to perform?\",options:[\"Classification\",\"Regression\",\"Clustering\",\"Anomaly detection\",\"Recommendation\",\"Natural language processing\"],category:\"Machine Learning Task\"},{question:\"What learning paradigm is most appropriate for your use case?\",options:[\"Supervised learning\",\"Unsupervised learning\",\"Semi-supervised learning\",\"Reinforcement learning\",\"Transfer learning\"],category:\"Learning Paradigm\"},{question:\"What is your priority regarding model complexity vs. interpretability?\",options:[\"High interpretability is essential\",\"Balance of interpretability and performance\",\"Performance is more important than interpretability\"],category:\"Constraints\"},{question:\"What computational resources are available for model training?\",options:[\"Limited (personal computer)\",\"Moderate (workstation)\",\"Substantial (dedicated servers)\",\"Extensive (cloud/distributed computing)\"],category:\"Constraints\"}],[AI_MODULES.REGULATION]:[{question:\"Is your AI system cataloged in your agency's use case inventory?\",options:[\"Yes, fully documented\",\"Partially documented\",\"Not yet documented\",\"Not applicable\"],category:\"Identification & Governance\",weight:1},{question:\"Has your agency designated leadership (e.g., Chief AI Officer) for AI governance?\",options:[\"Yes, with clear responsibilities\",\"Yes, but roles need clarification\",\"In progress\",\"No\"],category:\"Identification & Governance\",weight:1},{question:\"Has your AI system been reviewed by a governance board?\",options:[\"Yes, comprehensive review completed\",\"Partial review completed\",\"Review scheduled\",\"No review planned\"],category:\"Identification & Governance\",weight:1},{question:\"Does your AI system align with your agency's mission and statutory limits?\",options:[\"Yes, clearly aligned\",\"Mostly aligned with minor gaps\",\"Partially aligned with significant gaps\",\"Alignment not verified\"],category:\"Purpose & Use Justification\",weight:1},{question:\"Has a Risk-Based Impact Assessment (RBIA) been conducted for your AI system?\",options:[\"Yes, comprehensive assessment\",\"Partial assessment\",\"Assessment planned\",\"No assessment\"],category:\"Risk Assessment & Classification\",weight:1},{question:\"Is documentation about your AI model and datasets version-controlled?\",options:[\"Yes, comprehensive version control\",\"Partial version control\",\"Basic documentation without version control\",\"Limited or no documentation\"],category:\"Transparency & Explainability\",weight:1},{question:\"Does your AI system have human review mechanisms for key decisions?\",options:[\"Yes, robust human oversight\",\"Partial human oversight\",\"Limited human oversight\",\"No human oversight\"],category:\"Human Oversight & Accountability\",weight:1},{question:\"Has your Senior Agency Official for Privacy (SAOP) assessed the system?\",options:[\"Yes, thoroughly assessed\",\"Initial assessment completed\",\"Assessment planned\",\"No assessment\"],category:\"Privacy, Fairness & Data Integrity\",weight:1},{question:\"Does your system comply with FISMA and have Authority to Operate (ATO)?\",options:[\"Yes, full compliance with ATO\",\"Provisional ATO granted\",\"ATO in progress\",\"No ATO process initiated\"],category:\"Security & Robustness\",weight:1}],[AI_MODULES.RESPONSIBLE_AI]:[{question:\"Does your dataset reflect diverse populations with disaggregated metrics?\",options:[\"Yes, comprehensive diversity\",\"Moderate diversity\",\"Limited diversity\",\"Not evaluated\"],category:\"Bias & Fairness\",weight:1},{question:\"Have you performed fairness audits using metrics like disparate impact?\",options:[\"Yes, comprehensive audits\",\"Initial audits completed\",\"Planned but not executed\",\"No audits\"],category:\"Bias & Fairness\",weight:1},{question:\"Is your system compliant with relevant privacy regulations?\",options:[\"Yes, fully compliant\",\"Mostly compliant\",\"Partially compliant\",\"Compliance not verified\"],category:\"Privacy & Security\",weight:1},{question:\"Do you employ privacy-enhancing technologies (anonymization, differential privacy)?\",options:[\"Yes, multiple techniques\",\"Limited techniques\",\"Exploring options\",\"No techniques used\"],category:\"Privacy & Security\",weight:1},{question:\"Do you provide detailed documentation of model architecture and training?\",options:[\"Yes, comprehensive documentation\",\"Partial documentation\",\"Basic documentation\",\"Limited or no documentation\"],category:\"Transparency & Explainability\",weight:1},{question:\"Is responsibility for AI system performance clearly assigned?\",options:[\"Yes, clear ownership\",\"Partial ownership defined\",\"Informal ownership\",\"No defined ownership\"],category:\"Accountability\",weight:1},{question:\"Do you maintain audit trails for model outputs and changes?\",options:[\"Yes, comprehensive logs\",\"Partial logging\",\"Limited logging\",\"No logging\"],category:\"Accountability\",weight:1},{question:\"Have you evaluated system performance under edge cases and attacks?\",options:[\"Yes, comprehensive testing\",\"Limited testing\",\"Basic testing\",\"No testing\"],category:\"Robustness & Reliability\",weight:1},{question:\"Do you monitor for model drift and retrain as needed?\",options:[\"Yes, continuous monitoring\",\"Periodic monitoring\",\"Ad-hoc monitoring\",\"No monitoring\"],category:\"Robustness & Reliability\",weight:1},{question:\"Have you established fallback strategies for system failure?\",options:[\"Yes, comprehensive strategies\",\"Basic strategies\",\"Minimal planning\",\"No strategies\"],category:\"Robustness & Reliability\",weight:1}],[AI_MODULES.RISK]:[{question:\"Have you clearly defined the AI system's function, role, and objectives?\",options:[\"Yes, clearly defined\",\"Partially defined\",\"Vaguely defined\",\"Not defined\"],category:\"Map - Contextualization\",weight:1},{question:\"Have you identified and engaged key stakeholders (developers, users, impacted communities)?\",options:[\"Yes, comprehensive engagement\",\"Partial engagement\",\"Limited engagement\",\"No engagement\"],category:\"Map - Contextualization\",weight:1},{question:\"Have you assessed intended and unintended effects across the AI lifecycle?\",options:[\"Yes, comprehensive assessment\",\"Partial assessment\",\"Limited assessment\",\"No assessment\"],category:\"Map - Contextualization\",weight:1},{question:\"Are you using scenario planning, testing, and expert input for risk discovery?\",options:[\"Yes, all methods\",\"Some methods\",\"Limited methods\",\"No structured methods\"],category:\"Measure - Risk Identification & Evaluation\",weight:1},{question:\"Have you estimated consequences and probability of risk events?\",options:[\"Yes, detailed estimation\",\"Basic estimation\",\"Qualitative estimation only\",\"No estimation\"],category:\"Measure - Risk Identification & Evaluation\",weight:1},{question:\"Do you maintain and update a risk inventory?\",options:[\"Yes, regularly updated\",\"Occasionally updated\",\"Created but not updated\",\"No inventory\"],category:\"Measure - Risk Identification & Evaluation\",weight:1},{question:\"Have you documented controls and mitigation actions for identified risks?\",options:[\"Yes, comprehensive documentation\",\"Partial documentation\",\"Limited documentation\",\"No documentation\"],category:\"Manage - Risk Response\",weight:1},{question:\"Have you identified risk owners and maintained accountability?\",options:[\"Yes, clear ownership\",\"Partial ownership\",\"Informal ownership\",\"No defined ownership\"],category:\"Manage - Risk Response\",weight:1},{question:\"Have you created an oversight structure (boards or designated responsible parties)?\",options:[\"Yes, formal structure\",\"Informal structure\",\"Planning stage\",\"No structure\"],category:\"Govern - Oversight & Accountability\",weight:1},{question:\"Have you implemented audit trails and logs for accountability?\",options:[\"Yes, comprehensive implementation\",\"Partial implementation\",\"Limited implementation\",\"No implementation\"],category:\"Govern - Oversight & Accountability\",weight:1}]};// Mapping system recommendations based on user selections\nconst MODEL_RECOMMENDATIONS={\"Tabular data-Classification-Supervised learning\":{model:\"Random Forest, Gradient Boosting (XGBoost, LightGBM)\",rationale:\"These models handle tabular data well, provide good performance for classification tasks with supervised learning, and offer a balance of accuracy and interpretability.\"},\"Tabular data-Regression-Supervised learning\":{model:\"Linear Regression, ElasticNet, Gradient Boosting Regressors\",rationale:\"For tabular regression with supervised learning, these provide strong predictive performance while maintaining some interpretability.\"},\"Text data-Classification-Supervised learning\":{model:\"BERT, RoBERTa, DistilBERT fine-tuning\",rationale:\"Transformer-based models excel at text classification tasks, with various sizes to match computational constraints.\"},\"Image data-Classification-Supervised learning\":{model:\"ResNet, EfficientNet, Vision Transformer (ViT)\",rationale:\"These convolutional and transformer architectures are state-of-the-art for image classification tasks.\"},\"Time series data-Forecasting-Supervised learning\":{model:\"ARIMA, Prophet, LSTM, Temporal Fusion Transformer\",rationale:\"Specialized time series models from statistical to deep learning approaches, depending on data complexity.\"},\"Tabular data-Clustering-Unsupervised learning\":{model:\"K-Means, DBSCAN, Gaussian Mixture Models\",rationale:\"These algorithms excel at finding patterns and groupings in tabular data without labels.\"},\"Tabular data-Anomaly Detection-Unsupervised learning\":{model:\"Isolation Forest, One-Class SVM, Autoencoders\",rationale:\"These models can identify unusual patterns in data without needing examples of anomalies.\"}};// Calculate score and recommendation functions\nconst calculateModuleScore=(answers,module)=>{if(!answers||!answers[module]||Object.keys(answers[module]).length===0){return{score:0,maxScore:0,percentage:0};}const questions=QUESTIONNAIRES[module];let score=0;let maxScore=0;Object.entries(answers[module]).forEach(_ref=>{let[qIndex,answer]=_ref;const question=questions[parseInt(qIndex)];const optionIndex=question.options.indexOf(answer);const weight=question.weight||1;// Score based on option position (first option is best)\nconst optionScore=question.options.length-optionIndex;score+=optionScore*weight;maxScore+=question.options.length*weight;});const percentage=maxScore>0?Math.round(score/maxScore*100):0;return{score,maxScore,percentage};};const getComplianceLevel=percentage=>{if(percentage>=90)return{level:'High Compliance',color:'#4CAF50',icon:/*#__PURE__*/_jsx(CheckCircle,{size:20})};if(percentage>=70)return{level:'Moderate Compliance',color:'#FF9800',icon:/*#__PURE__*/_jsx(AlertTriangle,{size:20})};return{level:'Low Compliance',color:'#F44336',icon:/*#__PURE__*/_jsx(XCircle,{size:20})};};const getModelRecommendation=answers=>{if(!answers||!answers[AI_MODULES.MAPPING])return null;const mappingAnswers=answers[AI_MODULES.MAPPING];if(Object.keys(mappingAnswers).length<3)return null;const dataType=mappingAnswers[0];// Data modality\nconst taskType=mappingAnswers[1];// ML task\nconst learningType=mappingAnswers[2];// Learning paradigm\nconst key=`${dataType}-${taskType}-${learningType}`;return MODEL_RECOMMENDATIONS[key]||{model:\"Custom approach needed\",rationale:\"Your specific combination of requirements may need a tailored solution. Consider consulting with an ML specialist.\"};};// Create category scores for visualization\nconst getCategoryScores=(answers,module)=>{if(!answers||!answers[module]||Object.keys(answers[module]).length===0){return[];}const questions=QUESTIONNAIRES[module];const categories={};// Initialize categories\nquestions.forEach(q=>{if(!categories[q.category]){categories[q.category]={category:q.category,score:0,maxScore:0,percentage:0,questions:0,answeredQuestions:0};}categories[q.category].questions+=1;});// Calculate scores per category\nObject.entries(answers[module]).forEach(_ref2=>{let[qIndex,answer]=_ref2;const question=questions[parseInt(qIndex)];const category=question.category;const optionIndex=question.options.indexOf(answer);const weight=question.weight||1;// Score based on option position (first option is best)\nconst optionScore=question.options.length-optionIndex;categories[category].score+=optionScore*weight;categories[category].maxScore+=question.options.length*weight;categories[category].answeredQuestions+=1;});// Calculate percentages\nObject.values(categories).forEach(category=>{category.percentage=category.maxScore>0?Math.round(category.score/category.maxScore*100):0;});return Object.values(categories);};const Dashboard=()=>{const[activeModule,setActiveModule]=useState(AI_MODULES.MAPPING);const[moduleView,setModuleView]=useState('questionnaire');// 'questionnaire' or 'guide'\nconst[answers,setAnswers]=useState({[AI_MODULES.MAPPING]:{},[AI_MODULES.REGULATION]:{},[AI_MODULES.RESPONSIBLE_AI]:{},[AI_MODULES.RISK]:{}});const[showResults,setShowResults]=useState(false);const handleAnswer=(questionIndex,answer)=>{setAnswers(prev=>({...prev,[activeModule]:{...prev[activeModule],[questionIndex]:answer}}));};const handleModuleChange=module=>{setActiveModule(module);setShowResults(false);};const submitQuestionnaire=()=>{setShowResults(true);};const resetQuestionnaire=()=>{setAnswers(prev=>({...prev,[activeModule]:{}}));setShowResults(false);};const moduleScore=calculateModuleScore(answers,activeModule);const categoryScores=getCategoryScores(answers,activeModule);const complianceLevel=getComplianceLevel(moduleScore.percentage);const modelRecommendation=activeModule===AI_MODULES.MAPPING?getModelRecommendation(answers):null;return/*#__PURE__*/_jsxs(\"div\",{className:\"min-h-screen bg-gray-50\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"bg-white shadow p-4 mb-6\",children:[/*#__PURE__*/_jsx(\"h1\",{className:\"text-center text-2xl font-bold text-gray-800\",children:\"AI Governance Dashboard\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-center text-gray-600 mt-2\",children:\"Comprehensive AI System Assessment & Compliance Tool\"})]}),/*#__PURE__*/_jsx(\"div\",{className:\"container mx-auto px-4 pb-8\",children:/*#__PURE__*/_jsxs(\"div\",{className:\"flex flex-col md:flex-row gap-4\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"w-full md:w-1/4\",children:/*#__PURE__*/_jsxs(\"div\",{className:\"bg-white shadow rounded-lg p-4 h-full\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"text-xl font-medium mb-4\",children:\"Modules\"}),/*#__PURE__*/_jsx(\"ul\",{className:\"space-y-2\",children:Object.entries(AI_MODULES_INFO).map(_ref3=>{let[key,value]=_ref3;return/*#__PURE__*/_jsx(\"li\",{onClick:()=>handleModuleChange(key),className:`p-3 rounded-lg cursor-pointer ${activeModule===key?'bg-blue-100':'hover:bg-gray-100'}`,children:/*#__PURE__*/_jsxs(\"div\",{className:\"flex items-center\",children:[key===AI_MODULES.MAPPING&&/*#__PURE__*/_jsx(BarChart3,{size:20,className:\"mr-2 text-blue-500\"}),key===AI_MODULES.REGULATION&&/*#__PURE__*/_jsx(FileText,{size:20,className:\"mr-2 text-green-500\"}),key===AI_MODULES.RESPONSIBLE_AI&&/*#__PURE__*/_jsx(CheckCircle,{size:20,className:\"mr-2 text-purple-500\"}),key===AI_MODULES.RISK&&/*#__PURE__*/_jsx(AlertTriangle,{size:20,className:\"mr-2 text-orange-500\"}),/*#__PURE__*/_jsx(\"span\",{children:value.title})]})},key);})}),/*#__PURE__*/_jsx(\"hr\",{className:\"my-4\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"mt-4\",children:[/*#__PURE__*/_jsx(\"h3\",{className:\"font-medium mb-2\",children:\"Module Progress\"}),Object.entries(AI_MODULES_INFO).map(_ref4=>{let[key,value]=_ref4;const questionsAnswered=Object.keys(answers[key]).length;const totalQuestions=QUESTIONNAIRES[key].length;const progressPercentage=Math.round(questionsAnswered/totalQuestions*100);return/*#__PURE__*/_jsxs(\"div\",{className:\"mb-3\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"flex justify-between text-sm mb-1\",children:[/*#__PURE__*/_jsx(\"span\",{className:\"text-xs\",children:value.title}),/*#__PURE__*/_jsxs(\"span\",{className:\"text-xs\",children:[questionsAnswered,\"/\",totalQuestions]})]}),/*#__PURE__*/_jsx(\"div\",{className:\"w-full bg-gray-200 rounded-full h-2\",children:/*#__PURE__*/_jsx(\"div\",{className:\"h-2 rounded-full\",style:{width:`${progressPercentage}%`,backgroundColor:key===AI_MODULES.MAPPING?'#2196F3':key===AI_MODULES.REGULATION?'#4CAF50':key===AI_MODULES.RESPONSIBLE_AI?'#9C27B0':'#FF9800'}})})]},key);})]}),/*#__PURE__*/_jsx(\"div\",{className:\"mt-6 bg-blue-50 p-3 rounded-lg\",children:/*#__PURE__*/_jsxs(\"div\",{className:\"flex items-start\",children:[/*#__PURE__*/_jsx(Info,{size:20,className:\"mr-2 text-blue-500 mt-1\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-sm text-gray-700\",children:\"Complete all modules for a comprehensive AI governance assessment, or focus on specific areas of interest.\"})]})})]})}),/*#__PURE__*/_jsx(\"div\",{className:\"w-full md:w-3/4\",children:/*#__PURE__*/_jsxs(\"div\",{className:\"bg-white shadow rounded-lg mb-4\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"border-b p-4 flex justify-between items-center\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"text-xl font-medium\",children:AI_MODULES_INFO[activeModule].title}),/*#__PURE__*/_jsxs(\"div\",{children:[/*#__PURE__*/_jsx(\"button\",{className:`mr-2 ${moduleView==='questionnaire'?'bg-blue-600 text-white':'bg-gray-200'} px-3 py-1 rounded`,onClick:()=>setModuleView('questionnaire'),children:\"Questionnaire\"}),/*#__PURE__*/_jsx(\"button\",{className:`${moduleView==='guide'?'bg-blue-600 text-white':'bg-gray-200'} px-3 py-1 rounded`,onClick:()=>setModuleView('guide'),children:\"Information Guide\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"p-4 bg-blue-50 mb-4 flex items-start\",children:[/*#__PURE__*/_jsx(HelpCircle,{size:20,className:\"mr-2 text-blue-500 mt-1\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-sm\",children:AI_MODULES_INFO[activeModule].description})]}),moduleView==='questionnaire'?/*#__PURE__*/_jsxs(\"div\",{className:\"p-4\",children:[/*#__PURE__*/_jsx(\"h3\",{className:\"text-lg mb-4\",children:AI_MODULES_INFO[activeModule].questTitle}),!showResults?/*#__PURE__*/_jsxs(_Fragment,{children:[QUESTIONNAIRES[activeModule].map((q,index)=>/*#__PURE__*/_jsxs(\"div\",{className:\"mb-4 border rounded-lg overflow-hidden\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"bg-gray-100 p-4\",children:[/*#__PURE__*/_jsxs(\"h4\",{className:\"font-medium text-gray-800\",children:[index+1,\". \",q.question]}),/*#__PURE__*/_jsxs(\"p\",{className:\"text-sm text-gray-500\",children:[\"Category: \",q.category]})]}),/*#__PURE__*/_jsx(\"div\",{className:\"p-4\",children:/*#__PURE__*/_jsx(\"div\",{className:\"grid grid-cols-1 sm:grid-cols-2 md:grid-cols-4 gap-2\",children:q.options.map((option,optIndex)=>/*#__PURE__*/_jsx(\"button\",{className:`p-2 border rounded w-full ${answers[activeModule][index]===option?'bg-blue-600 text-white':'border-gray-300'}`,onClick:()=>handleAnswer(index,option),children:option},optIndex))})})]},index)),/*#__PURE__*/_jsxs(\"div\",{className:\"mt-6 flex justify-between\",children:[/*#__PURE__*/_jsx(\"button\",{className:\"bg-gray-300 hover:bg-gray-400 text-gray-800 px-4 py-2 rounded\",onClick:resetQuestionnaire,children:\"Reset\"}),/*#__PURE__*/_jsx(\"button\",{className:\"bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded\",onClick:submitQuestionnaire,children:\"Submit\"})]})]}):/*#__PURE__*/// Results view\n_jsxs(\"div\",{children:[/*#__PURE__*/_jsxs(\"div\",{className:\"mb-6 border rounded-lg overflow-hidden\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"bg-blue-50 p-4 border-b\",children:/*#__PURE__*/_jsx(\"h3\",{className:\"text-xl font-bold\",children:\"Assessment Results\"})}),/*#__PURE__*/_jsxs(\"div\",{className:\"p-4\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"mb-4\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-2\",children:\"Overall Compliance Score\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex items-center mb-2\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-grow\",children:/*#__PURE__*/_jsx(\"div\",{className:\"w-full bg-gray-200 rounded-full h-2.5\",children:/*#__PURE__*/_jsx(\"div\",{className:\"h-2.5 rounded-full\",style:{width:`${moduleScore.percentage}%`,backgroundColor:complianceLevel.color}})})}),/*#__PURE__*/_jsxs(\"span\",{className:\"ml-4 font-bold\",children:[moduleScore.percentage,\"%\"]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex items-center\",children:[/*#__PURE__*/_jsx(\"span\",{className:\"mr-2\",style:{color:complianceLevel.color},children:complianceLevel.icon}),/*#__PURE__*/_jsx(\"span\",{style:{color:complianceLevel.color},children:complianceLevel.level})]})]}),activeModule!==AI_MODULES.MAPPING&&/*#__PURE__*/_jsxs(\"div\",{className:\"mt-8\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-4\",children:\"Category Breakdown\"}),/*#__PURE__*/_jsx(\"div\",{className:\"h-64\",children:/*#__PURE__*/_jsx(ResponsiveContainer,{width:\"100%\",height:\"100%\",children:activeModule===AI_MODULES.RESPONSIBLE_AI?/*#__PURE__*/_jsxs(RadarChart,{outerRadius:90,data:categoryScores,children:[/*#__PURE__*/_jsx(PolarGrid,{}),/*#__PURE__*/_jsx(PolarAngleAxis,{dataKey:\"category\"}),/*#__PURE__*/_jsx(PolarRadiusAxis,{domain:[0,100]}),/*#__PURE__*/_jsx(Radar,{name:\"Score\",dataKey:\"percentage\",stroke:\"#8884d8\",fill:\"#8884d8\",fillOpacity:0.6}),/*#__PURE__*/_jsx(Tooltip,{formatter:value=>[`${value}%`,'Score']})]}):/*#__PURE__*/_jsxs(BarChart,{data:categoryScores,children:[/*#__PURE__*/_jsx(CartesianGrid,{strokeDasharray:\"3 3\"}),/*#__PURE__*/_jsx(XAxis,{dataKey:\"category\"}),/*#__PURE__*/_jsx(YAxis,{domain:[0,100]}),/*#__PURE__*/_jsx(Tooltip,{formatter:value=>[`${value}%`,'Score']}),/*#__PURE__*/_jsx(Legend,{}),/*#__PURE__*/_jsx(Bar,{dataKey:\"percentage\",name:\"Compliance Score\",fill:\"#8884d8\"})]})})})]}),activeModule===AI_MODULES.MAPPING&&modelRecommendation&&/*#__PURE__*/_jsxs(\"div\",{className:\"mt-6 p-4 bg-blue-50 rounded-lg\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-bold mb-2\",children:\"Recommended Model\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-xl font-medium mb-2 text-blue-800\",children:modelRecommendation.model}),/*#__PURE__*/_jsx(\"p\",{className:\"text-gray-700\",children:modelRecommendation.rationale})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"mt-8\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-2\",children:\"Areas for Improvement\"}),/*#__PURE__*/_jsxs(\"ul\",{className:\"space-y-2\",children:[categoryScores.filter(cat=>cat.percentage<70).map((cat,index)=>/*#__PURE__*/_jsxs(\"li\",{className:\"rounded bg-gray-50 p-4\",children:[/*#__PURE__*/_jsx(\"p\",{className:\"font-medium\",children:cat.category}),/*#__PURE__*/_jsxs(\"p\",{className:\"text-sm text-gray-600\",children:[\"Current score: \",cat.percentage,\"% - \",cat.answeredQuestions,\"/\",cat.questions,\" questions answered\"]})]},index)),categoryScores.filter(cat=>cat.percentage<70).length===0&&/*#__PURE__*/_jsx(\"p\",{className:\"text-green-600 italic\",children:\"All categories show good compliance levels!\"})]})]})]})]}),/*#__PURE__*/_jsx(\"button\",{className:\"mt-4 bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded\",onClick:()=>setShowResults(false),children:\"Return to Questionnaire\"})]})]}):/*#__PURE__*/// Guide view\n_jsxs(\"div\",{className:\"p-4\",children:[/*#__PURE__*/_jsx(\"h3\",{className:\"text-lg mb-4\",children:AI_MODULES_INFO[activeModule].guideTitle}),GUIDE_CONTENT[activeModule].map((section,index)=>/*#__PURE__*/_jsxs(\"div\",{className:\"mb-4 border rounded-lg overflow-hidden\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"bg-gray-100 p-4 flex justify-between items-center cursor-pointer\",onClick:()=>{const element=document.getElementById(`section-${index}`);if(element){element.style.display=element.style.display==='none'?'block':'none';}},children:[/*#__PURE__*/_jsx(\"h4\",{className:\"font-medium\",children:section.title}),/*#__PURE__*/_jsx(ChevronDown,{})]}),/*#__PURE__*/_jsx(\"div\",{id:`section-${index}`,className:\"p-4\",children:/*#__PURE__*/_jsx(\"ul\",{className:\"space-y-2\",children:section.items.map((item,itemIndex)=>/*#__PURE__*/_jsxs(\"li\",{className:\"flex py-2\",children:[/*#__PURE__*/_jsx(\"span\",{className:\"mr-2 text-blue-500\",children:\"\\u2022\"}),/*#__PURE__*/_jsx(\"span\",{children:item})]},itemIndex))})})]},index)),activeModule===AI_MODULES.RESPONSIBLE_AI&&/*#__PURE__*/_jsxs(\"div\",{className:\"mt-6\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-4\",children:\"Responsible AI Principles Framework\"}),/*#__PURE__*/_jsx(\"div\",{className:\"h-64\",children:/*#__PURE__*/_jsx(ResponsiveContainer,{width:\"100%\",height:\"100%\",children:/*#__PURE__*/_jsxs(RadarChart,{outerRadius:90,data:[{area:\"Bias & Fairness\",fullMark:100,value:100},{area:\"Privacy & Security\",fullMark:100,value:100},{area:\"Transparency\",fullMark:100,value:100},{area:\"Accountability\",fullMark:100,value:100},{area:\"Robustness\",fullMark:100,value:100}],children:[/*#__PURE__*/_jsx(PolarGrid,{}),/*#__PURE__*/_jsx(PolarAngleAxis,{dataKey:\"area\"}),/*#__PURE__*/_jsx(PolarRadiusAxis,{domain:[0,100]}),/*#__PURE__*/_jsx(Radar,{name:\"Framework\",dataKey:\"value\",stroke:\"#8884d8\",fill:\"#8884d8\",fillOpacity:0.6})]})})})]}),activeModule===AI_MODULES.RISK&&/*#__PURE__*/_jsxs(\"div\",{className:\"mt-6\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-4\",children:\"NIST AI RMF Core Functions\"}),/*#__PURE__*/_jsx(\"div\",{className:\"flex flex-wrap justify-center\",children:[\"Map\",\"Measure\",\"Manage\",\"Govern\"].map((func,idx)=>/*#__PURE__*/_jsx(\"div\",{className:\"m-2 p-4 w-40 h-40 rounded-full flex flex-col items-center justify-center text-center bg-blue-100 border-2 border-blue-500\",children:/*#__PURE__*/_jsx(\"span\",{className:\"font-bold text-blue-800\",children:func})},idx))})]}),activeModule===AI_MODULES.MAPPING&&/*#__PURE__*/_jsxs(\"div\",{className:\"mt-6\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-4\",children:\"Model Selection Framework\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"relative w-full h-64 border rounded-lg overflow-hidden\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"absolute left-0 top-0 w-1/2 h-1/2 bg-blue-100 border-r border-b p-4\",children:[/*#__PURE__*/_jsx(\"p\",{className:\"font-bold\",children:\"Data Modality\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-sm\",children:\"Structured vs. Unstructured\"})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"absolute right-0 top-0 w-1/2 h-1/2 bg-green-100 border-l border-b p-4\",children:[/*#__PURE__*/_jsx(\"p\",{className:\"font-bold\",children:\"Task Type\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-sm\",children:\"Classification, Regression, etc.\"})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"absolute left-0 bottom-0 w-1/2 h-1/2 bg-yellow-100 border-r border-t p-4\",children:[/*#__PURE__*/_jsx(\"p\",{className:\"font-bold\",children:\"Learning Paradigm\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-sm\",children:\"Supervised, Unsupervised, etc.\"})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"absolute right-0 bottom-0 w-1/2 h-1/2 bg-purple-100 border-l border-t p-4\",children:[/*#__PURE__*/_jsx(\"p\",{className:\"font-bold\",children:\"Constraints\"}),/*#__PURE__*/_jsx(\"p\",{className:\"text-sm\",children:\"Resources, Interpretability, etc.\"})]})]})]}),activeModule===AI_MODULES.REGULATION&&/*#__PURE__*/_jsxs(\"div\",{className:\"mt-6\",children:[/*#__PURE__*/_jsx(\"h4\",{className:\"text-lg font-medium mb-4\",children:\"Federal AI Policy Pillars\"}),/*#__PURE__*/_jsx(\"div\",{className:\"h-64\",children:/*#__PURE__*/_jsx(ResponsiveContainer,{width:\"100%\",height:\"100%\",children:/*#__PURE__*/_jsxs(BarChart,{data:[{name:\"Governance\",value:100},{name:\"Transparency\",value:100},{name:\"Accountability\",value:100},{name:\"Privacy\",value:100},{name:\"Security\",value:100},{name:\"Fairness\",value:100}],children:[/*#__PURE__*/_jsx(CartesianGrid,{strokeDasharray:\"3 3\"}),/*#__PURE__*/_jsx(XAxis,{dataKey:\"name\"}),/*#__PURE__*/_jsx(YAxis,{domain:[0,100]}),/*#__PURE__*/_jsx(Tooltip,{}),/*#__PURE__*/_jsx(Bar,{dataKey:\"value\",fill:\"#8884d8\"})]})})})]})]})]})})]})})]});};export default Dashboard;","map":{"version":3,"names":["React","useState","BarChart","Bar","XAxis","YAxis","CartesianGrid","Tooltip","Legend","ResponsiveContainer","RadarChart","PolarGrid","PolarAngleAxis","PolarRadiusAxis","Radar","Info","CheckCircle","AlertTriangle","XCircle","HelpCircle","ChevronDown","BarChart3","FileText","jsx","_jsx","jsxs","_jsxs","Fragment","_Fragment","AI_MODULES","MAPPING","REGULATION","RESPONSIBLE_AI","RISK","AI_MODULES_INFO","title","description","guideTitle","questTitle","GUIDE_CONTENT","items","QUESTIONNAIRES","question","options","category","weight","MODEL_RECOMMENDATIONS","model","rationale","calculateModuleScore","answers","module","Object","keys","length","score","maxScore","percentage","questions","entries","forEach","_ref","qIndex","answer","parseInt","optionIndex","indexOf","optionScore","Math","round","getComplianceLevel","level","color","icon","size","getModelRecommendation","mappingAnswers","dataType","taskType","learningType","key","getCategoryScores","categories","q","answeredQuestions","_ref2","values","Dashboard","activeModule","setActiveModule","moduleView","setModuleView","setAnswers","showResults","setShowResults","handleAnswer","questionIndex","prev","handleModuleChange","submitQuestionnaire","resetQuestionnaire","moduleScore","categoryScores","complianceLevel","modelRecommendation","className","children","map","_ref3","value","onClick","_ref4","questionsAnswered","totalQuestions","progressPercentage","style","width","backgroundColor","index","option","optIndex","height","outerRadius","data","dataKey","domain","name","stroke","fill","fillOpacity","formatter","strokeDasharray","filter","cat","section","element","document","getElementById","display","id","item","itemIndex","area","fullMark","func","idx"],"sources":["/Users/atul/Documents/GitHub/ai-governance-dashboard/src/App.js"],"sourcesContent":["import React, { useState } from 'react';\nimport { BarChart, Bar, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer, RadarChart, PolarGrid, PolarAngleAxis, PolarRadiusAxis, Radar } from 'recharts';\nimport { Info, CheckCircle, AlertTriangle, XCircle, HelpCircle, ChevronDown, BarChart3, FileText } from 'lucide-react';\n\nconst AI_MODULES = {\n  MAPPING: 'ai-mapping',\n  REGULATION: 'ai-regulation',\n  RESPONSIBLE_AI: 'responsible-ai',\n  RISK: 'ai-risk'\n};\n\nconst AI_MODULES_INFO = {\n  [AI_MODULES.MAPPING]: {\n    title: 'AI Model Mapping',\n    description: 'Match machine learning models to application needs based on data modality, task type, learning paradigm, and constraints.',\n    guideTitle: 'AI Model Mapping Guide',\n    questTitle: 'ML Model Selection Questionnaire'\n  },\n  [AI_MODULES.REGULATION]: {\n    title: 'AI Regulation & Policy',\n    description: 'Ensure compliance with federal AI regulations and policies for responsible and transparent AI governance.',\n    guideTitle: 'Federal AI Regulations Guide',\n    questTitle: 'Federal AI Compliance Questionnaire'\n  },\n  [AI_MODULES.RESPONSIBLE_AI]: {\n    title: 'Responsible AI',\n    description: 'Apply the five core principles of Responsible AI: Bias & Fairness, Privacy & Security, Transparency, Accountability, and Robustness.',\n    guideTitle: 'Responsible AI Principles Guide',\n    questTitle: 'Responsible AI Compliance Questionnaire'\n  },\n  [AI_MODULES.RISK]: {\n    title: 'AI Risk Management',\n    description: 'Identify, evaluate, respond to, and govern AI risks through the NIST AI Risk Management Framework.',\n    guideTitle: 'NIST AI RMF Guide',\n    questTitle: 'AI RMF Risk Assessment Questionnaire'\n  }\n};\n\n// Information guides content\nconst GUIDE_CONTENT = {\n  [AI_MODULES.MAPPING]: [\n    {\n      title: 'Data Modality',\n      items: [\n        'Tabular data: Structured data in tables with rows and columns. This includes CSV files, database tables, and spreadsheets. Common in business applications, financial systems, and enterprise environments where data is highly structured and follows a schema.',\n        'Text data: Unstructured or semi-structured data such as articles, documents, reviews, emails, and chat logs. These require natural language processing techniques and typically benefit from transformer-based models that can understand semantic meaning.',\n        'Image data: Pixel-based data including grayscale and RGB images, medical scans, satellite imagery, and video frames. Convolutional neural networks excel with these inputs by detecting spatial patterns and hierarchical features.',\n        'Time series data: Sequential data points collected over time, such as sensor readings, stock prices, IoT device metrics, and user activity logs. Temporal patterns and seasonality are key features that specialized algorithms can detect.'\n      ]\n    },\n    {\n      title: 'Machine Learning Task',\n      items: [\n        'Classification: Assigning data to predefined categories or classes. Examples include spam detection, sentiment analysis, disease diagnosis, and object recognition. Classification models output discrete labels or probabilities of class membership, with metrics like accuracy, precision, recall, and F1 score used for evaluation.',\n        'Regression: Predicting continuous numerical values based on input features. Use cases include price prediction, demand forecasting, and resource allocation. These models output real numbers rather than categories, with performance measured by metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.',\n        'Clustering: Grouping similar data points together without predefined labels. Used for customer segmentation, anomaly detection, and document organization. Algorithms like K-means, DBSCAN, and hierarchical clustering identify natural groupings in data based on similarity or distance measures.',\n        'Anomaly Detection: Identifying rare, unusual, or suspicious data instances that deviate significantly from the norm. Critical for fraud detection, network security, manufacturing quality control, and system health monitoring. These models learn what \"normal\" patterns look like and flag deviations.'\n      ]\n    },\n    {\n      title: 'Learning Paradigm',\n      items: [\n        'Supervised learning: Learning from labeled data with known outcomes. The model is trained on input-output pairs (features and target labels/values) and learns to predict outputs for new inputs. This is the most common approach, suitable when you have sufficient labeled data and clear target variables. Examples include image classification, sentiment analysis, and spam filtering.',\n        'Unsupervised learning: Learning patterns and structures from unlabeled data without explicit guidance. The algorithm discovers hidden patterns, groupings, or representations in data. Used when labeled data is unavailable or expensive to obtain, or when exploring unknown patterns. Examples include clustering, dimensionality reduction, and anomaly detection.',\n        'Semi-supervised learning: Learning from a mix of labeled and unlabeled data. This hybrid approach leverages small amounts of labeled data with larger amounts of unlabeled data. Particularly valuable when obtaining labeled data is expensive or time-consuming. Common in medical imaging, speech recognition, and text classification where partial labeling is feasible.',\n        'Reinforcement learning: Learning optimal actions through trial-and-error interactions with an environment. The model (agent) learns by receiving rewards or penalties based on its actions. Used for sequential decision-making problems like robotics, game playing, autonomous vehicles, and resource management. Differs from other paradigms by focusing on long-term rewards rather than immediate prediction accuracy.'\n      ]\n    },\n    {\n      title: 'Constraints',\n      items: [\n        'Model complexity: The sophistication of the model and interpretability trade-offs. Simpler models (linear regression, decision trees) are more explainable but may underfit complex data. Complex models (deep neural networks, ensemble methods) can capture intricate patterns but function as \"black boxes,\" creating challenges for explainability, regulatory compliance, and stakeholder trust. Consider your explainability requirements carefully when selecting model architecture.',\n        'Training resources: Amount of computational power, memory, time, and expertise needed. Resource requirements increase with data size, model complexity, and hyperparameter tuning needs. Consider your available infrastructure (CPUs, GPUs, TPUs, cloud resources), time constraints, and budget. Remember that resource-intensive models also typically require specialized expertise to develop and maintain.',\n        'Inference speed: How quickly the model can make predictions after deployment. Critical for real-time applications like autonomous vehicles, fraud detection, and recommendation systems. Models with fast inference may require optimization techniques like quantization, pruning, distillation, or specialized hardware. Consider latency requirements, throughput needs, and deployment environment constraints (edge devices, browser-based, server-side).',\n        'Operational considerations: Additional factors like model maintainability, retraining frequency, data pipeline complexity, and integration with existing systems. Consider the full lifecycle of your model, including monitoring for drift, versioning, A/B testing capabilities, and compliance with organizational policies and industry regulations.'\n      ]\n    }\n  ],\n  [AI_MODULES.REGULATION]: [\n    {\n      title: 'Identification & Governance',\n      items: [\n        'System Inventory: AI systems must be cataloged in the agency\\'s use case inventory. This inventory should include comprehensive metadata about each AI system, including purpose, data sources, development methodology, deployment status, and risk classification. Regular audits should ensure the inventory remains current as systems evolve or new ones are developed.',\n        'Designated Leadership: Each agency must have a Chief AI Officer and governance lead who is accountable for AI risk management and compliance. This leadership role should have sufficient authority, resources, and expertise to effectively oversee AI activities across the organization. The CAIO typically reports to senior leadership and coordinates with privacy, security, and ethics officers.',\n        'Review by AI Board: Governance boards should evaluate rights-impacting or high-risk systems through a structured review process. These cross-functional boards typically include legal, technical, ethics, and domain experts who conduct thorough assessments before deployment and during operation. High-risk systems require more rigorous review, including potential red-team exercises and independent verification.'\n      ]\n    },\n    {\n      title: 'Purpose & Use Justification',\n      items: [\n        'Mission Alignment: AI use must support federal missions and not contradict statutory limits. Agencies should clearly document how each AI system furthers specific mission objectives and operates within legal boundaries. This requires collaboration between technical teams, legal counsel, and policy experts to ensure both technical capabilities and implementation approaches align with the agency\\'s authorized activities and avoid mission creep or statutory violations.',\n        'Rights-Impacting Assessment: Evaluate if the AI system affects individual rights or access to benefits. Systems that influence decisions about individuals—especially in areas like benefits determination, law enforcement, immigration, or public services—require heightened scrutiny. This assessment should analyze potential impacts on constitutional rights, civil liberties, privacy, and equitable access to government services, with special attention to effects on marginalized communities.',\n        'Public Disclosure: Purpose and function must be stated in clear, accessible language. Agencies must provide transparency about AI systems through public-facing documentation that avoids technical jargon. This disclosure should include the system\\'s purpose, capabilities, limitations, data sources (at an appropriate level of detail), and how it fits into agency decision-making processes. For sensitive systems, disclosures should provide meaningful transparency while respecting security and privacy constraints.'\n      ]\n    },\n    {\n      title: 'Risk Assessment & Classification',\n      items: [\n        'Risk-Based Impact Assessment (RBIA): Conducted to classify systems as low, moderate, or high impact. This formal assessment evaluates potential harms across multiple dimensions including rights and safety impacts, scope of deployment, autonomy level, and technical maturity. The resulting classification determines the governance requirements, with high-impact systems subject to more stringent controls. RBIA should consider both likelihood and severity of potential harms, with special attention to irreversible impacts.',\n        'Independent Evaluation: External reviews or red-teaming are encouraged for high-risk systems. Third-party assessments provide valuable independent verification of risk controls and can identify blind spots missed by internal teams. For high-impact systems, these evaluations should include adversarial testing, stress testing with edge cases, and evaluation of fairness across demographic groups. Independent reviewers should have appropriate expertise and sufficient access to system details.',\n        'Ongoing Monitoring: Risks should be evaluated before and after deployment, with regular reassessments throughout the system lifecycle. Initial risk assessments are insufficient; agencies must implement continuous monitoring to detect emergent risks, performance degradation, or concept drift. This includes establishing key risk indicators, threshold alerts, regular risk reviews, and post-incident analyses to ensure risks remain within acceptable tolerances and to identify new mitigation strategies as the operational environment evolves.'\n      ]\n    },\n    {\n      title: 'Transparency & Explainability',\n      items: [\n        'Documentation: Models and datasets must be documented and version-controlled. This documentation should include model architecture, training methodology, performance metrics, testing procedures, known limitations, data sources, and preprocessing steps. Model cards and datasheets are emerging standards that provide structured templates for thorough documentation. Version control should track all changes to models and data, including retraining cycles, with the ability to roll back to previous versions if issues arise.',\n        'Explainability: AI outputs should be understandable to users, especially for critical decisions. Agencies must provide appropriate explanations tailored to different stakeholder needs—from technical details for specialists to clear reasoning for affected individuals. Explainability approaches should be proportional to the system\\'s impact and complexity. For high-impact systems, agencies should implement layered explanations that provide both overview-level and detailed justifications for outcomes.',\n        'Interpretability Tools: Use SHAP, LIME, or similar techniques to explain high-stakes predictions. For complex models like neural networks, these interpretability methods help identify which features most influence specific predictions. Tools should be selected based on the model type, use case, and stakeholder needs. For critical systems, agencies should implement multiple complementary interpretability approaches, as each method has different strengths and limitations. These tools should be incorporated into user interfaces where appropriate to provide real-time explanations.'\n      ]\n    },\n    {\n      title: 'Human Oversight & Accountability',\n      items: [\n        'Human-in-the-Loop: Ensure human review of key AI-driven decisions.',\n        'Redress Mechanisms: Establish paths for affected individuals to challenge outcomes.',\n        'Personnel Training: Operators must be trained in ethical AI use and escalation protocols.'\n      ]\n    },\n    {\n      title: 'Privacy, Fairness & Data Integrity',\n      items: [\n        'SAOP Involvement: The Senior Agency Official for Privacy must assess the system.',\n        'Bias Audits: Fairness audits should assess disparate impact and demographic performance.',\n        'Data Governance: Demographic and sensitive data use must be justified and documented.'\n      ]\n    },\n    {\n      title: 'Security & Robustness',\n      items: [\n        'ATO Compliance: Systems must comply with FISMA and receive Authority to Operate.',\n        'Security Controls: Safeguards against adversarial attacks and data leakage must be in place.',\n        'Performance Drift: Detect and mitigate performance decay and concept drift.'\n      ]\n    },\n    {\n      title: 'Public Services & High-Impact Systems',\n      items: [\n        'High-Impact Services: Systems affecting public service delivery must meet additional standards.',\n        'Public Redress: Feedback and correction mechanisms should be made available.',\n        'IQA Compliance: Systems must meet Information Quality Act requirements.'\n      ]\n    },\n    {\n      title: 'Lifecycle & Open Source Considerations',\n      items: [\n        'Documentation Maintenance: Training, testing, and deployment documents must be up to date.',\n        'Decommissioning Plans: There should be a plan for system retirement or replacement.',\n        'Open Source Evaluation: Source code should be published when feasible and not restricted.'\n      ]\n    }\n  ],\n  [AI_MODULES.RESPONSIBLE_AI]: [\n    {\n      title: 'Bias & Fairness',\n      items: [\n        'Dataset Representativeness: Ensure datasets reflect diverse populations and use disaggregated metrics. This requires careful data collection and curation to include adequate representation across relevant demographic groups. Organizations should document dataset composition, identify potential gaps or underrepresented groups, and supplement data where necessary. Disaggregated metrics involve analyzing model performance separately for different subgroups to identify disparities that might be hidden in aggregate statistics.',\n        'Bias Audits: Perform fairness audits using metrics like disparate impact or equal opportunity. Fairness audits should be conducted throughout the AI lifecycle—during development, before deployment, and regularly in production. Organizations should select appropriate fairness metrics based on the specific context and use case. Common metrics include demographic parity, equal opportunity, equalized odds, and counterfactual fairness. The results of these audits should inform model modifications and deployment decisions.',\n        'Fairness Constraints: Apply fairness-aware methods during training and evaluation. These methods can include pre-processing techniques (modifying training data to reduce bias), in-processing approaches (incorporating fairness objectives directly into model training), and post-processing methods (adjusting model outputs to ensure fair results). Organizations should document which fairness definitions and constraints they prioritize, as different fairness metrics can sometimes be mathematically incompatible.',\n        'Disparate Impact Monitoring: Evaluate model behavior across subgroups to identify differential performance. This involves regular testing across demographic categories and protected attributes to uncover unintended discrimination. Organizations should establish thresholds for acceptable performance differences and implement alerting systems when disparities exceed these thresholds. For high-risk applications, consider using formal disparate impact analysis frameworks from legal and regulatory contexts.',\n        'Unfair Outcome Mitigation: Establish procedures to detect and resolve inequitable results. Create clear protocols for addressing fairness issues when discovered, including potential model updates, additional controls, or human review processes. Define escalation paths and response timelines based on the severity of fairness concerns. Mitigation strategies should be documented and evaluated for effectiveness. Organizations should maintain a library of fairness issues and their resolutions to build institutional knowledge.'\n      ]\n    },\n    {\n      title: 'Privacy & Security',\n      items: [\n        'Sensitive Data Protection: Ensure compliance with privacy regulations and minimize sensitive data use. Organizations should inventory all data used in AI systems, classify data sensitivity levels, and implement appropriate controls based on data type. This includes meeting requirements from regulations like GDPR, HIPAA, CCPA, and federal privacy laws. Sensitive data minimization principles should apply throughout the AI lifecycle—from collection to processing, storage, and retention. Organizations should document data flows and implement privacy impact assessments for high-risk systems.',\n        'Privacy-Enhancing Technologies (PETs): Use techniques like anonymization, differential privacy, or secure multiparty computation to protect individual privacy while maintaining utility. These technologies allow organizations to derive insights from sensitive data while minimizing privacy risks. Differential privacy adds mathematical noise to protect individual records while preserving statistical validity. Federated learning enables model training across distributed datasets without centralizing sensitive data. Homomorphic encryption allows computation on encrypted data without decryption.',\n        'Access Controls: Restrict access to models and outputs to authorized individuals based on least privilege principles. Implement role-based access controls, authentication mechanisms, and audit logging for all system interactions. For sensitive AI systems, consider implementing multi-factor authentication and privileged access management. Access permissions should be regularly reviewed and updated as roles change. AI outputs containing sensitive information should inherit the protection level of the underlying data.',\n        'Adversarial Defense: Protect against model manipulation, data poisoning, and inference attacks. Organizations should implement defenses against various attack vectors, including adversarial examples (inputs designed to cause misclassification), model inversion (reconstructing training data), and membership inference (determining if data was used in training). Defense strategies include adversarial training, input validation, model distillation, and regularization techniques that enhance model robustness.',\n        'External Audits: Conduct third-party reviews and penetration testing to identify vulnerabilities. Independent security assessments provide objective evaluation of security controls and identify gaps that internal teams might miss. For high-risk systems, organizations should implement a regular cadence of security audits, including penetration testing, model security reviews, and privacy assessments. Results should inform security improvements and be incorporated into organizational risk management processes.'\n      ]\n    },\n    {\n      title: 'Transparency & Explainability',\n      items: [\n        'Model Documentation: Provide detailed records of model architecture, training, and assumptions.',\n        'User-Facing Explanations: Offer explanations tailored to different stakeholder groups.',\n        'Interpretability Tools: Incorporate SHAP, LIME, or counterfactuals for complex models.',\n        'Non-Technical Communication: Use accessible language for public understanding.',\n        'Lifecycle Transparency: Keep documentation up to date through development and deployment.'\n      ]\n    },\n    {\n      title: 'Accountability',\n      items: [\n        'Ownership: Assign responsibility for AI system development, performance, and oversight.',\n        'Appeal Mechanisms: Allow users to contest or appeal AI-generated decisions.',\n        'Audit Trails: Log model outputs, training changes, and deployment events.',\n        'Governance Processes: Ensure models are reviewed by internal or external ethics boards.',\n        'Public Disclosure: Publish contact, policy, and impact information for accountability.'\n      ]\n    },\n    {\n      title: 'Robustness & Reliability',\n      items: [\n        'Stress Testing: Evaluate performance under edge cases and simulated attacks.',\n        'Monitoring & Maintenance: Track drift and accuracy over time and retrain as needed.',\n        'Fallback Strategies: Plan for system failure modes with safe alternatives.',\n        'Environment Testing: Validate behavior in varied and real-world contexts.',\n        'Operational Readiness: Confirm model stability prior to deployment.'\n      ]\n    }\n  ],\n  [AI_MODULES.RISK]: [\n    {\n      title: 'Map - Contextualization',\n      items: [\n        'Purpose Clarity: Define the AI system\\'s function, role, and objectives with precision and specificity. This goes beyond simple descriptions to articulate exactly what the system is designed to do, its capabilities and limitations, and how it will be used in practice. The purpose statement should address the problem being solved, value proposition, intended users, and societal implications. This clarity is foundational for all subsequent risk assessment activities.',\n        'Stakeholder Identification: Engage developers, users, and impacted communities throughout the AI lifecycle. Stakeholder mapping should identify both direct stakeholders (users, operators, decision-makers) and indirect stakeholders (communities affected by decisions, marginalized groups, regulatory bodies). Engagement should be proportional to risk level and include diverse perspectives. For high-impact systems, consider creating formal advisory panels with representatives from affected communities.',\n        'Impact Mapping: Assess intended and unintended effects across the AI lifecycle using structured methodologies. This includes identifying primary, secondary, and tertiary impacts across social, economic, environmental, and ethical dimensions. Organizations should use techniques like scenario planning and consequence scanning to anticipate unexpected outcomes. Impact assessment should span from development through deployment, ongoing operation, and eventual decommissioning or replacement.',\n        'Legal/Ethical Fit: Confirm alignment with agency mission, legal boundaries, and ethical frameworks. This involves detailed analysis of relevant laws, regulations, ethical guidelines, and organizational values. For each identified risk, map applicable legal requirements and ethical principles. Document where compliance is required versus where ethical considerations go beyond legal minimums. This analysis should inform go/no-go decisions for AI development and deployment.',\n        'System Interactions: Document all system dependencies, integrations, and environmental interactions. Create comprehensive maps of how the AI system connects with other systems, data sources, and human workflows. This includes technical dependencies, operational relationships, and potential cascade effects. Understanding these interconnections is crucial for identifying emergent risks that arise from system interactions rather than from individual components.'\n      ]\n    },\n    {\n      title: 'Measure - Risk Identification & Evaluation',\n      items: [\n        'Risk Discovery Methods: Use scenario planning, testing, and expert input to systematically identify potential risks. Effective risk discovery employs multiple complementary methods, including red team exercises, tabletop scenarios, failure mode analysis, and expert workshops. Organizations should consider both known risks from similar systems and novel risks specific to the application context. For high-impact systems, implement participatory approaches that include diverse stakeholders in the risk identification process.',\n        'Severity and Likelihood Assessment: Estimate consequences and probability of risk events using both quantitative and qualitative methods. Develop impact scales that consider dimensions such as harm severity, number of people affected, duration of impact, and reversibility. Create likelihood scales based on historical data where available and structured expert judgment where needed. Risk prioritization should consider both dimensions, with special attention to low-probability, high-consequence events that could cause catastrophic harm.',\n        'Conditional Performance Evaluation: Assess accuracy under varied inputs and conditions to understand performance boundaries. Test model behavior across different subpopulations, edge cases, and adversarial scenarios. Identify conditions where performance degrades significantly, which represents hidden risk. For safety-critical applications, stress testing should evaluate performance under low-frequency but high-risk scenarios, including rare input patterns and system failures.',\n        'Comprehensive Metrics: Include fairness, robustness, privacy, and reliability measures beyond standard accuracy metrics. Develop a balanced scorecard of metrics relevant to the specific application context and stakeholder concerns. For each metric, establish thresholds that define acceptable performance levels and trigger points for intervention. Monitor trade-offs between competing objectives, such as privacy versus utility or performance versus explainability.',\n        'Risk Tracking: Maintain and update a comprehensive risk inventory throughout the AI lifecycle. The risk register should document each identified risk, its assessment, mitigations, ownership, and current status. Implement regular review cycles to update risk assessments as the system, its usage, or operating environment evolves. For high-impact systems, integrate AI risk tracking with enterprise risk management processes for appropriate governance oversight.'\n      ]\n    },\n    {\n      title: 'Manage - Risk Response',\n      items: [\n        'Mitigation Planning: Document controls and mitigation actions for each identified risk. Develop a structured response strategy that may include risk acceptance (for low-impact risks within tolerance), avoidance (eliminating the risk source), transfer (sharing risk through insurance or partnerships), or reduction (implementing controls to lower probability or impact). For each mitigation, document implementation approach, required resources, timeline, and expected risk reduction. Mitigation plans should be proportional to risk level and address root causes where possible.',\n        'Responsibility Assignment: Identify risk owners and maintain clear accountability throughout the AI lifecycle. Each identified risk should have a designated owner with appropriate authority and resources to implement mitigations. Responsibilities should span technical teams, business units, legal/compliance, and executive leadership based on risk nature and severity. Document roles in risk governance, including who approves risk acceptance decisions at different thresholds and who is responsible for ongoing monitoring and escalation.',\n        'Dynamic Risk Register: Keep risk logs updated and accessible to support active risk management. The risk register should be a living document that evolves as risks change, new risks emerge, and mitigations are implemented. Include risk descriptions, assessments, controls, status, review dates, and audit trail of changes. For complex or high-impact systems, consider implementing specialized AI risk management tools that can track risks across multiple dimensions and link to related artifacts.',\n        'Incident Escalation: Set clear thresholds and response protocols for emergent risks and incidents. Define triggers for different escalation levels based on impact severity, vulnerability exploitation, or performance degradation. Document notification requirements, response team composition, and decision authority at each escalation level. For high-impact systems, conduct regular incident response exercises to test protocols and improve organizational readiness.',\n        'Effectiveness Testing: Test risk mitigations for performance to verify they function as intended. Implement both pre-deployment validation and post-implementation monitoring of control effectiveness. For critical controls, conduct periodic testing under realistic conditions, including potential circumvention attempts. When mitigations prove less effective than expected, adjust the approach and document lessons learned to improve future risk management practices.'\n      ]\n    },\n    {\n      title: 'Govern - Oversight & Accountability',\n      items: [\n        'Governance Structure: Create oversight boards or designate responsible parties with clear authority and reporting lines. Effective AI governance requires formal structures with appropriate expertise, diversity, and decision-making authority. For organizations developing or deploying multiple AI systems, consider tiered governance with system-specific reviews feeding into enterprise-level oversight. Governance bodies should include technical expertise, domain knowledge, ethics perspectives, and legal/compliance representation to ensure comprehensive risk management.',\n        'Policy Integration: Align AI use with broader organizational policies on data governance, security, privacy, and ethics. AI governance should not exist in isolation but should connect to existing organizational frameworks. Document how AI-specific policies interact with enterprise risk management, information security, privacy, procurement, and compliance policies. This integration ensures consistency in risk approach and leverages existing controls where appropriate.',\n        'Audit Mechanisms: Use audit trails and logs for accountability throughout the AI lifecycle. Implement technical logging to capture key model behaviors, data access, and system changes. Document decision points, approvals, and policy exceptions. For high-impact systems, consider implementing immutable audit trails to prevent tampering. Automated monitoring and alerting should complement human review processes to flag anomalies or policy violations.',\n        'Ethical & Legal Oversight: Ensure adherence to AI governance frameworks, ethical guidelines, and legal mandates. Develop processes to monitor evolving regulations and standards in AI governance. Conduct regular compliance assessments against applicable laws, regulations, and ethical frameworks. Document how system design and operational controls address specific requirements, and maintain evidence of compliance for potential regulatory review.',\n        'Transparency Practices: Share relevant risk insights with internal and external stakeholders through appropriate channels. Determine what information should be shared with different stakeholder groups—from technical details for regulators to accessible summaries for affected communities. For public-facing systems, publish appropriate documentation about system purpose, capabilities, limitations, and governance. For internal systems, ensure decision-makers understand key risk factors and controls.'\n      ]\n    }\n  ]\n};\n\n// Sample questionnaires for each module\nconst QUESTIONNAIRES = {\n  [AI_MODULES.MAPPING]: [\n    {\n      question: \"What type of data will your AI system primarily process?\",\n      options: [\"Tabular data\", \"Text data\", \"Image data\", \"Time series data\", \"Audio data\", \"Mixed data types\"],\n      category: \"Data Modality\"\n    },\n    {\n      question: \"What is the primary task your AI system needs to perform?\",\n      options: [\"Classification\", \"Regression\", \"Clustering\", \"Anomaly detection\", \"Recommendation\", \"Natural language processing\"],\n      category: \"Machine Learning Task\"\n    },\n    {\n      question: \"What learning paradigm is most appropriate for your use case?\",\n      options: [\"Supervised learning\", \"Unsupervised learning\", \"Semi-supervised learning\", \"Reinforcement learning\", \"Transfer learning\"],\n      category: \"Learning Paradigm\"\n    },\n    {\n      question: \"What is your priority regarding model complexity vs. interpretability?\",\n      options: [\"High interpretability is essential\", \"Balance of interpretability and performance\", \"Performance is more important than interpretability\"],\n      category: \"Constraints\"\n    },\n    {\n      question: \"What computational resources are available for model training?\",\n      options: [\"Limited (personal computer)\", \"Moderate (workstation)\", \"Substantial (dedicated servers)\", \"Extensive (cloud/distributed computing)\"],\n      category: \"Constraints\"\n    }\n  ],\n  [AI_MODULES.REGULATION]: [\n    {\n      question: \"Is your AI system cataloged in your agency's use case inventory?\",\n      options: [\"Yes, fully documented\", \"Partially documented\", \"Not yet documented\", \"Not applicable\"],\n      category: \"Identification & Governance\",\n      weight: 1\n    },\n    {\n      question: \"Has your agency designated leadership (e.g., Chief AI Officer) for AI governance?\",\n      options: [\"Yes, with clear responsibilities\", \"Yes, but roles need clarification\", \"In progress\", \"No\"],\n      category: \"Identification & Governance\",\n      weight: 1\n    },\n    {\n      question: \"Has your AI system been reviewed by a governance board?\",\n      options: [\"Yes, comprehensive review completed\", \"Partial review completed\", \"Review scheduled\", \"No review planned\"],\n      category: \"Identification & Governance\",\n      weight: 1\n    },\n    {\n      question: \"Does your AI system align with your agency's mission and statutory limits?\",\n      options: [\"Yes, clearly aligned\", \"Mostly aligned with minor gaps\", \"Partially aligned with significant gaps\", \"Alignment not verified\"],\n      category: \"Purpose & Use Justification\",\n      weight: 1\n    },\n    {\n      question: \"Has a Risk-Based Impact Assessment (RBIA) been conducted for your AI system?\",\n      options: [\"Yes, comprehensive assessment\", \"Partial assessment\", \"Assessment planned\", \"No assessment\"],\n      category: \"Risk Assessment & Classification\",\n      weight: 1\n    },\n    {\n      question: \"Is documentation about your AI model and datasets version-controlled?\",\n      options: [\"Yes, comprehensive version control\", \"Partial version control\", \"Basic documentation without version control\", \"Limited or no documentation\"],\n      category: \"Transparency & Explainability\",\n      weight: 1\n    },\n    {\n      question: \"Does your AI system have human review mechanisms for key decisions?\",\n      options: [\"Yes, robust human oversight\", \"Partial human oversight\", \"Limited human oversight\", \"No human oversight\"],\n      category: \"Human Oversight & Accountability\",\n      weight: 1\n    },\n    {\n      question: \"Has your Senior Agency Official for Privacy (SAOP) assessed the system?\",\n      options: [\"Yes, thoroughly assessed\", \"Initial assessment completed\", \"Assessment planned\", \"No assessment\"],\n      category: \"Privacy, Fairness & Data Integrity\",\n      weight: 1\n    },\n    {\n      question: \"Does your system comply with FISMA and have Authority to Operate (ATO)?\",\n      options: [\"Yes, full compliance with ATO\", \"Provisional ATO granted\", \"ATO in progress\", \"No ATO process initiated\"],\n      category: \"Security & Robustness\",\n      weight: 1\n    }\n  ],\n  [AI_MODULES.RESPONSIBLE_AI]: [\n    {\n      question: \"Does your dataset reflect diverse populations with disaggregated metrics?\",\n      options: [\"Yes, comprehensive diversity\", \"Moderate diversity\", \"Limited diversity\", \"Not evaluated\"],\n      category: \"Bias & Fairness\",\n      weight: 1\n    },\n    {\n      question: \"Have you performed fairness audits using metrics like disparate impact?\",\n      options: [\"Yes, comprehensive audits\", \"Initial audits completed\", \"Planned but not executed\", \"No audits\"],\n      category: \"Bias & Fairness\",\n      weight: 1\n    },\n    {\n      question: \"Is your system compliant with relevant privacy regulations?\",\n      options: [\"Yes, fully compliant\", \"Mostly compliant\", \"Partially compliant\", \"Compliance not verified\"],\n      category: \"Privacy & Security\",\n      weight: 1\n    },\n    {\n      question: \"Do you employ privacy-enhancing technologies (anonymization, differential privacy)?\",\n      options: [\"Yes, multiple techniques\", \"Limited techniques\", \"Exploring options\", \"No techniques used\"],\n      category: \"Privacy & Security\",\n      weight: 1\n    },\n    {\n      question: \"Do you provide detailed documentation of model architecture and training?\",\n      options: [\"Yes, comprehensive documentation\", \"Partial documentation\", \"Basic documentation\", \"Limited or no documentation\"],\n      category: \"Transparency & Explainability\",\n      weight: 1\n    },\n    {\n      question: \"Is responsibility for AI system performance clearly assigned?\",\n      options: [\"Yes, clear ownership\", \"Partial ownership defined\", \"Informal ownership\", \"No defined ownership\"],\n      category: \"Accountability\",\n      weight: 1\n    },\n    {\n      question: \"Do you maintain audit trails for model outputs and changes?\",\n      options: [\"Yes, comprehensive logs\", \"Partial logging\", \"Limited logging\", \"No logging\"],\n      category: \"Accountability\",\n      weight: 1\n    },\n    {\n      question: \"Have you evaluated system performance under edge cases and attacks?\",\n      options: [\"Yes, comprehensive testing\", \"Limited testing\", \"Basic testing\", \"No testing\"],\n      category: \"Robustness & Reliability\",\n      weight: 1\n    },\n    {\n      question: \"Do you monitor for model drift and retrain as needed?\",\n      options: [\"Yes, continuous monitoring\", \"Periodic monitoring\", \"Ad-hoc monitoring\", \"No monitoring\"],\n      category: \"Robustness & Reliability\",\n      weight: 1\n    },\n    {\n      question: \"Have you established fallback strategies for system failure?\",\n      options: [\"Yes, comprehensive strategies\", \"Basic strategies\", \"Minimal planning\", \"No strategies\"],\n      category: \"Robustness & Reliability\",\n      weight: 1\n    }\n  ],\n  [AI_MODULES.RISK]: [\n    {\n      question: \"Have you clearly defined the AI system's function, role, and objectives?\",\n      options: [\"Yes, clearly defined\", \"Partially defined\", \"Vaguely defined\", \"Not defined\"],\n      category: \"Map - Contextualization\",\n      weight: 1\n    },\n    {\n      question: \"Have you identified and engaged key stakeholders (developers, users, impacted communities)?\",\n      options: [\"Yes, comprehensive engagement\", \"Partial engagement\", \"Limited engagement\", \"No engagement\"],\n      category: \"Map - Contextualization\",\n      weight: 1\n    },\n    {\n      question: \"Have you assessed intended and unintended effects across the AI lifecycle?\",\n      options: [\"Yes, comprehensive assessment\", \"Partial assessment\", \"Limited assessment\", \"No assessment\"],\n      category: \"Map - Contextualization\",\n      weight: 1\n    },\n    {\n      question: \"Are you using scenario planning, testing, and expert input for risk discovery?\",\n      options: [\"Yes, all methods\", \"Some methods\", \"Limited methods\", \"No structured methods\"],\n      category: \"Measure - Risk Identification & Evaluation\",\n      weight: 1\n    },\n    {\n      question: \"Have you estimated consequences and probability of risk events?\",\n      options: [\"Yes, detailed estimation\", \"Basic estimation\", \"Qualitative estimation only\", \"No estimation\"],\n      category: \"Measure - Risk Identification & Evaluation\",\n      weight: 1\n    },\n    {\n      question: \"Do you maintain and update a risk inventory?\",\n      options: [\"Yes, regularly updated\", \"Occasionally updated\", \"Created but not updated\", \"No inventory\"],\n      category: \"Measure - Risk Identification & Evaluation\",\n      weight: 1\n    },\n    {\n      question: \"Have you documented controls and mitigation actions for identified risks?\",\n      options: [\"Yes, comprehensive documentation\", \"Partial documentation\", \"Limited documentation\", \"No documentation\"],\n      category: \"Manage - Risk Response\",\n      weight: 1\n    },\n    {\n      question: \"Have you identified risk owners and maintained accountability?\",\n      options: [\"Yes, clear ownership\", \"Partial ownership\", \"Informal ownership\", \"No defined ownership\"],\n      category: \"Manage - Risk Response\",\n      weight: 1\n    },\n    {\n      question: \"Have you created an oversight structure (boards or designated responsible parties)?\",\n      options: [\"Yes, formal structure\", \"Informal structure\", \"Planning stage\", \"No structure\"],\n      category: \"Govern - Oversight & Accountability\",\n      weight: 1\n    },\n    {\n      question: \"Have you implemented audit trails and logs for accountability?\",\n      options: [\"Yes, comprehensive implementation\", \"Partial implementation\", \"Limited implementation\", \"No implementation\"],\n      category: \"Govern - Oversight & Accountability\",\n      weight: 1\n    }\n  ]\n};\n\n// Mapping system recommendations based on user selections\nconst MODEL_RECOMMENDATIONS = {\n  \"Tabular data-Classification-Supervised learning\": {\n    model: \"Random Forest, Gradient Boosting (XGBoost, LightGBM)\",\n    rationale: \"These models handle tabular data well, provide good performance for classification tasks with supervised learning, and offer a balance of accuracy and interpretability.\"\n  },\n  \"Tabular data-Regression-Supervised learning\": {\n    model: \"Linear Regression, ElasticNet, Gradient Boosting Regressors\",\n    rationale: \"For tabular regression with supervised learning, these provide strong predictive performance while maintaining some interpretability.\"\n  },\n  \"Text data-Classification-Supervised learning\": {\n    model: \"BERT, RoBERTa, DistilBERT fine-tuning\",\n    rationale: \"Transformer-based models excel at text classification tasks, with various sizes to match computational constraints.\"\n  },\n  \"Image data-Classification-Supervised learning\": {\n    model: \"ResNet, EfficientNet, Vision Transformer (ViT)\",\n    rationale: \"These convolutional and transformer architectures are state-of-the-art for image classification tasks.\"\n  },\n  \"Time series data-Forecasting-Supervised learning\": {\n    model: \"ARIMA, Prophet, LSTM, Temporal Fusion Transformer\",\n    rationale: \"Specialized time series models from statistical to deep learning approaches, depending on data complexity.\"\n  },\n  \"Tabular data-Clustering-Unsupervised learning\": {\n    model: \"K-Means, DBSCAN, Gaussian Mixture Models\",\n    rationale: \"These algorithms excel at finding patterns and groupings in tabular data without labels.\"\n  },\n  \"Tabular data-Anomaly Detection-Unsupervised learning\": {\n    model: \"Isolation Forest, One-Class SVM, Autoencoders\",\n    rationale: \"These models can identify unusual patterns in data without needing examples of anomalies.\"\n  }\n};\n\n// Calculate score and recommendation functions\nconst calculateModuleScore = (answers, module) => {\n  if (!answers || !answers[module] || Object.keys(answers[module]).length === 0) {\n    return { score: 0, maxScore: 0, percentage: 0 };\n  }\n  \n  const questions = QUESTIONNAIRES[module];\n  let score = 0;\n  let maxScore = 0;\n  \n  Object.entries(answers[module]).forEach(([qIndex, answer]) => {\n    const question = questions[parseInt(qIndex)];\n    const optionIndex = question.options.indexOf(answer);\n    const weight = question.weight || 1;\n    \n    // Score based on option position (first option is best)\n    const optionScore = question.options.length - optionIndex;\n    score += optionScore * weight;\n    maxScore += question.options.length * weight;\n  });\n  \n  const percentage = maxScore > 0 ? Math.round((score / maxScore) * 100) : 0;\n  \n  return { score, maxScore, percentage };\n};\n\nconst getComplianceLevel = (percentage) => {\n  if (percentage >= 90) return { level: 'High Compliance', color: '#4CAF50', icon: <CheckCircle size={20} /> };\n  if (percentage >= 70) return { level: 'Moderate Compliance', color: '#FF9800', icon: <AlertTriangle size={20} /> };\n  return { level: 'Low Compliance', color: '#F44336', icon: <XCircle size={20} /> };\n};\n\nconst getModelRecommendation = (answers) => {\n  if (!answers || !answers[AI_MODULES.MAPPING]) return null;\n  \n  const mappingAnswers = answers[AI_MODULES.MAPPING];\n  if (Object.keys(mappingAnswers).length < 3) return null;\n  \n  const dataType = mappingAnswers[0]; // Data modality\n  const taskType = mappingAnswers[1]; // ML task\n  const learningType = mappingAnswers[2]; // Learning paradigm\n  \n  const key = `${dataType}-${taskType}-${learningType}`;\n  return MODEL_RECOMMENDATIONS[key] || {\n    model: \"Custom approach needed\",\n    rationale: \"Your specific combination of requirements may need a tailored solution. Consider consulting with an ML specialist.\"\n  };\n};\n\n// Create category scores for visualization\nconst getCategoryScores = (answers, module) => {\n  if (!answers || !answers[module] || Object.keys(answers[module]).length === 0) {\n    return [];\n  }\n  \n  const questions = QUESTIONNAIRES[module];\n  const categories = {};\n  \n  // Initialize categories\n  questions.forEach(q => {\n    if (!categories[q.category]) {\n      categories[q.category] = { \n        category: q.category, \n        score: 0, \n        maxScore: 0, \n        percentage: 0,\n        questions: 0,\n        answeredQuestions: 0\n      };\n    }\n    categories[q.category].questions += 1;\n  });\n  \n  // Calculate scores per category\n  Object.entries(answers[module]).forEach(([qIndex, answer]) => {\n    const question = questions[parseInt(qIndex)];\n    const category = question.category;\n    const optionIndex = question.options.indexOf(answer);\n    const weight = question.weight || 1;\n    \n    // Score based on option position (first option is best)\n    const optionScore = question.options.length - optionIndex;\n    \n    categories[category].score += optionScore * weight;\n    categories[category].maxScore += question.options.length * weight;\n    categories[category].answeredQuestions += 1;\n  });\n  \n  // Calculate percentages\n  Object.values(categories).forEach(category => {\n    category.percentage = category.maxScore > 0 \n      ? Math.round((category.score / category.maxScore) * 100) \n      : 0;\n  });\n  \n  return Object.values(categories);\n};\n\nconst Dashboard = () => {\n  const [activeModule, setActiveModule] = useState(AI_MODULES.MAPPING);\n  const [moduleView, setModuleView] = useState('questionnaire'); // 'questionnaire' or 'guide'\n  const [answers, setAnswers] = useState({\n    [AI_MODULES.MAPPING]: {},\n    [AI_MODULES.REGULATION]: {},\n    [AI_MODULES.RESPONSIBLE_AI]: {},\n    [AI_MODULES.RISK]: {}\n  });\n  const [showResults, setShowResults] = useState(false);\n  \n  const handleAnswer = (questionIndex, answer) => {\n    setAnswers(prev => ({\n      ...prev,\n      [activeModule]: {\n        ...prev[activeModule],\n        [questionIndex]: answer\n      }\n    }));\n  };\n  \n  const handleModuleChange = (module) => {\n    setActiveModule(module);\n    setShowResults(false);\n  };\n  \n  const submitQuestionnaire = () => {\n    setShowResults(true);\n  };\n  \n  const resetQuestionnaire = () => {\n    setAnswers(prev => ({\n      ...prev,\n      [activeModule]: {}\n    }));\n    setShowResults(false);\n  };\n  \n  const moduleScore = calculateModuleScore(answers, activeModule);\n  const categoryScores = getCategoryScores(answers, activeModule);\n  const complianceLevel = getComplianceLevel(moduleScore.percentage);\n  const modelRecommendation = activeModule === AI_MODULES.MAPPING ? getModelRecommendation(answers) : null;\n  \n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      {/* Header */}\n      <div className=\"bg-white shadow p-4 mb-6\">\n        <h1 className=\"text-center text-2xl font-bold text-gray-800\">AI Governance Dashboard</h1>\n        <p className=\"text-center text-gray-600 mt-2\">Comprehensive AI System Assessment & Compliance Tool</p>\n      </div>\n      \n      <div className=\"container mx-auto px-4 pb-8\">\n        <div className=\"flex flex-col md:flex-row gap-4\">\n          {/* Sidebar */}\n          <div className=\"w-full md:w-1/4\">\n            <div className=\"bg-white shadow rounded-lg p-4 h-full\">\n              <h2 className=\"text-xl font-medium mb-4\">Modules</h2>\n              <ul className=\"space-y-2\">\n                {Object.entries(AI_MODULES_INFO).map(([key, value]) => (\n                  <li \n                    key={key}\n                    onClick={() => handleModuleChange(key)}\n                    className={`p-3 rounded-lg cursor-pointer ${activeModule === key ? 'bg-blue-100' : 'hover:bg-gray-100'}`}\n                  >\n                    <div className=\"flex items-center\">\n                      {key === AI_MODULES.MAPPING && <BarChart3 size={20} className=\"mr-2 text-blue-500\" />}\n                      {key === AI_MODULES.REGULATION && <FileText size={20} className=\"mr-2 text-green-500\" />}\n                      {key === AI_MODULES.RESPONSIBLE_AI && <CheckCircle size={20} className=\"mr-2 text-purple-500\" />}\n                      {key === AI_MODULES.RISK && <AlertTriangle size={20} className=\"mr-2 text-orange-500\" />}\n                      <span>{value.title}</span>\n                    </div>\n                  </li>\n                ))}\n              </ul>\n              \n              <hr className=\"my-4\" />\n              \n              <div className=\"mt-4\">\n                <h3 className=\"font-medium mb-2\">Module Progress</h3>\n                {Object.entries(AI_MODULES_INFO).map(([key, value]) => {\n                  const questionsAnswered = Object.keys(answers[key]).length;\n                  const totalQuestions = QUESTIONNAIRES[key].length;\n                  const progressPercentage = Math.round((questionsAnswered / totalQuestions) * 100);\n                  \n                  return (\n                    <div key={key} className=\"mb-3\">\n                      <div className=\"flex justify-between text-sm mb-1\">\n                        <span className=\"text-xs\">{value.title}</span>\n                        <span className=\"text-xs\">{questionsAnswered}/{totalQuestions}</span>\n                      </div>\n                      <div className=\"w-full bg-gray-200 rounded-full h-2\">\n                        <div \n                          className=\"h-2 rounded-full\" \n                          style={{\n                            width: `${progressPercentage}%`,\n                            backgroundColor: key === AI_MODULES.MAPPING ? '#2196F3' :\n                                          key === AI_MODULES.REGULATION ? '#4CAF50' :\n                                          key === AI_MODULES.RESPONSIBLE_AI ? '#9C27B0' : '#FF9800'\n                          }}\n                        ></div>\n                      </div>\n                    </div>\n                  );\n                })}\n              </div>\n              \n              <div className=\"mt-6 bg-blue-50 p-3 rounded-lg\">\n                <div className=\"flex items-start\">\n                  <Info size={20} className=\"mr-2 text-blue-500 mt-1\" />\n                  <p className=\"text-sm text-gray-700\">\n                    Complete all modules for a comprehensive AI governance assessment, or focus on specific areas of interest.\n                  </p>\n                </div>\n              </div>\n            </div>\n          </div>\n          \n          {/* Main Content */}\n          <div className=\"w-full md:w-3/4\">\n            <div className=\"bg-white shadow rounded-lg mb-4\">\n              <div className=\"border-b p-4 flex justify-between items-center\">\n                <h2 className=\"text-xl font-medium\">{AI_MODULES_INFO[activeModule].title}</h2>\n                <div>\n                  <button \n                    className={`mr-2 ${moduleView === 'questionnaire' ? 'bg-blue-600 text-white' : 'bg-gray-200'} px-3 py-1 rounded`}\n                    onClick={() => setModuleView('questionnaire')}\n                  >\n                    Questionnaire\n                  </button>\n                  <button \n                    className={`${moduleView === 'guide' ? 'bg-blue-600 text-white' : 'bg-gray-200'} px-3 py-1 rounded`}\n                    onClick={() => setModuleView('guide')}\n                  >\n                    Information Guide\n                  </button>\n                </div>\n              </div>\n              \n              <div className=\"p-4 bg-blue-50 mb-4 flex items-start\">\n                <HelpCircle size={20} className=\"mr-2 text-blue-500 mt-1\" />\n                <p className=\"text-sm\">\n                  {AI_MODULES_INFO[activeModule].description}\n                </p>\n              </div>\n              \n              {moduleView === 'questionnaire' ? (\n                <div className=\"p-4\">\n                  <h3 className=\"text-lg mb-4\">{AI_MODULES_INFO[activeModule].questTitle}</h3>\n                  \n                  {!showResults ? (\n                    <>\n                      {QUESTIONNAIRES[activeModule].map((q, index) => (\n                        <div key={index} className=\"mb-4 border rounded-lg overflow-hidden\">\n                          <div className=\"bg-gray-100 p-4\">\n                            <h4 className=\"font-medium text-gray-800\">\n                              {index + 1}. {q.question}\n                            </h4>\n                            <p className=\"text-sm text-gray-500\">\n                              Category: {q.category}\n                            </p>\n                          </div>\n                          <div className=\"p-4\">\n                            <div className=\"grid grid-cols-1 sm:grid-cols-2 md:grid-cols-4 gap-2\">\n                              {q.options.map((option, optIndex) => (\n                                <button\n                                  key={optIndex}\n                                  className={`p-2 border rounded w-full ${answers[activeModule][index] === option ? 'bg-blue-600 text-white' : 'border-gray-300'}`}\n                                  onClick={() => handleAnswer(index, option)}\n                                >\n                                  {option}\n                                </button>\n                              ))}\n                            </div>\n                          </div>\n                        </div>\n                      ))}\n                      \n                      <div className=\"mt-6 flex justify-between\">\n                        <button \n                          className=\"bg-gray-300 hover:bg-gray-400 text-gray-800 px-4 py-2 rounded\"\n                          onClick={resetQuestionnaire}\n                        >\n                          Reset\n                        </button>\n                        <button \n                          className=\"bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded\"\n                          onClick={submitQuestionnaire}\n                        >\n                          Submit\n                        </button>\n                      </div>\n                    </>\n                  ) : (\n                    // Results view\n                    <div>\n                      <div className=\"mb-6 border rounded-lg overflow-hidden\">\n                        <div className=\"bg-blue-50 p-4 border-b\">\n                          <h3 className=\"text-xl font-bold\">Assessment Results</h3>\n                        </div>\n                        <div className=\"p-4\">\n                          <div className=\"mb-4\">\n                            <h4 className=\"text-lg font-medium mb-2\">Overall Compliance Score</h4>\n                            <div className=\"flex items-center mb-2\">\n                              <div className=\"flex-grow\">\n                                <div className=\"w-full bg-gray-200 rounded-full h-2.5\">\n                                  <div \n                                    className=\"h-2.5 rounded-full\" \n                                    style={{ \n                                      width: `${moduleScore.percentage}%`,\n                                      backgroundColor: complianceLevel.color\n                                    }}\n                                  ></div>\n                                </div>\n                              </div>\n                              <span className=\"ml-4 font-bold\">\n                                {moduleScore.percentage}%\n                              </span>\n                            </div>\n                            <div className=\"flex items-center\">\n                              <span className=\"mr-2\" style={{ color: complianceLevel.color }}>\n                                {complianceLevel.icon}\n                              </span>\n                              <span style={{ color: complianceLevel.color }}>\n                                {complianceLevel.level}\n                              </span>\n                            </div>\n                          </div>\n                          \n                          {activeModule !== AI_MODULES.MAPPING && (\n                            <div className=\"mt-8\">\n                              <h4 className=\"text-lg font-medium mb-4\">Category Breakdown</h4>\n                              <div className=\"h-64\">\n                                <ResponsiveContainer width=\"100%\" height=\"100%\">\n                                  {activeModule === AI_MODULES.RESPONSIBLE_AI ? (\n                                    <RadarChart outerRadius={90} data={categoryScores}>\n                                      <PolarGrid />\n                                      <PolarAngleAxis dataKey=\"category\" />\n                                      <PolarRadiusAxis domain={[0, 100]} />\n                                      <Radar name=\"Score\" dataKey=\"percentage\" stroke=\"#8884d8\" fill=\"#8884d8\" fillOpacity={0.6} />\n                                      <Tooltip formatter={(value) => [`${value}%`, 'Score']} />\n                                    </RadarChart>\n                                  ) : (\n                                    <BarChart data={categoryScores}>\n                                      <CartesianGrid strokeDasharray=\"3 3\" />\n                                      <XAxis dataKey=\"category\" />\n                                      <YAxis domain={[0, 100]} />\n                                      <Tooltip formatter={(value) => [`${value}%`, 'Score']} />\n                                      <Legend />\n                                      <Bar dataKey=\"percentage\" name=\"Compliance Score\" fill=\"#8884d8\" />\n                                    </BarChart>\n                                  )}\n                                </ResponsiveContainer>\n                              </div>\n                            </div>\n                          )}\n                          \n                          {activeModule === AI_MODULES.MAPPING && modelRecommendation && (\n                            <div className=\"mt-6 p-4 bg-blue-50 rounded-lg\">\n                              <h4 className=\"text-lg font-bold mb-2\">Recommended Model</h4>\n                              <p className=\"text-xl font-medium mb-2 text-blue-800\">{modelRecommendation.model}</p>\n                              <p className=\"text-gray-700\">{modelRecommendation.rationale}</p>\n                            </div>\n                          )}\n                          \n                          <div className=\"mt-8\">\n                            <h4 className=\"text-lg font-medium mb-2\">Areas for Improvement</h4>\n                            <ul className=\"space-y-2\">\n                              {categoryScores\n                                .filter(cat => cat.percentage < 70)\n                                .map((cat, index) => (\n                                  <li key={index} className=\"rounded bg-gray-50 p-4\">\n                                    <p className=\"font-medium\">{cat.category}</p>\n                                    <p className=\"text-sm text-gray-600\">\n                                      Current score: {cat.percentage}% - {cat.answeredQuestions}/{cat.questions} questions answered\n                                    </p>\n                                  </li>\n                                ))}\n                              {categoryScores.filter(cat => cat.percentage < 70).length === 0 && (\n                                <p className=\"text-green-600 italic\">\n                                  All categories show good compliance levels!\n                                </p>\n                              )}\n                            </ul>\n                          </div>\n                        </div>\n                      </div>\n                      \n                      <button \n                        className=\"mt-4 bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded\"\n                        onClick={() => setShowResults(false)}\n                      >\n                        Return to Questionnaire\n                      </button>\n                    </div>\n                  )}\n                </div>\n              ) : (\n                // Guide view\n                <div className=\"p-4\">\n                  <h3 className=\"text-lg mb-4\">{AI_MODULES_INFO[activeModule].guideTitle}</h3>\n                  \n                  {GUIDE_CONTENT[activeModule].map((section, index) => (\n                    <div key={index} className=\"mb-4 border rounded-lg overflow-hidden\">\n                      <div \n                        className=\"bg-gray-100 p-4 flex justify-between items-center cursor-pointer\"\n                        onClick={() => {\n                          const element = document.getElementById(`section-${index}`);\n                          if (element) {\n                            element.style.display = element.style.display === 'none' ? 'block' : 'none';\n                          }\n                        }}\n                      >\n                        <h4 className=\"font-medium\">{section.title}</h4>\n                        <ChevronDown />\n                      </div>\n                      <div id={`section-${index}`} className=\"p-4\">\n                        <ul className=\"space-y-2\">\n                          {section.items.map((item, itemIndex) => (\n                            <li key={itemIndex} className=\"flex py-2\">\n                              <span className=\"mr-2 text-blue-500\">•</span>\n                              <span>{item}</span>\n                            </li>\n                          ))}\n                        </ul>\n                      </div>\n                    </div>\n                  ))}\n                  \n                  {activeModule === AI_MODULES.RESPONSIBLE_AI && (\n                    <div className=\"mt-6\">\n                      <h4 className=\"text-lg font-medium mb-4\">Responsible AI Principles Framework</h4>\n                      <div className=\"h-64\">\n                        <ResponsiveContainer width=\"100%\" height=\"100%\">\n                          <RadarChart \n                            outerRadius={90} \n                            data={[\n                              { area: \"Bias & Fairness\", fullMark: 100, value: 100 },\n                              { area: \"Privacy & Security\", fullMark: 100, value: 100 },\n                              { area: \"Transparency\", fullMark: 100, value: 100 },\n                              { area: \"Accountability\", fullMark: 100, value: 100 },\n                              { area: \"Robustness\", fullMark: 100, value: 100 }\n                            ]}\n                          >\n                            <PolarGrid />\n                            <PolarAngleAxis dataKey=\"area\" />\n                            <PolarRadiusAxis domain={[0, 100]} />\n                            <Radar name=\"Framework\" dataKey=\"value\" stroke=\"#8884d8\" fill=\"#8884d8\" fillOpacity={0.6} />\n                          </RadarChart>\n                        </ResponsiveContainer>\n                      </div>\n                    </div>\n                  )}\n                  \n                  {activeModule === AI_MODULES.RISK && (\n                    <div className=\"mt-6\">\n                      <h4 className=\"text-lg font-medium mb-4\">NIST AI RMF Core Functions</h4>\n                      <div className=\"flex flex-wrap justify-center\">\n                        {[\"Map\", \"Measure\", \"Manage\", \"Govern\"].map((func, idx) => (\n                          <div key={idx} className=\"m-2 p-4 w-40 h-40 rounded-full flex flex-col items-center justify-center text-center bg-blue-100 border-2 border-blue-500\">\n                            <span className=\"font-bold text-blue-800\">{func}</span>\n                          </div>\n                        ))}\n                      </div>\n                    </div>\n                  )}\n                  \n                  {activeModule === AI_MODULES.MAPPING && (\n                    <div className=\"mt-6\">\n                      <h4 className=\"text-lg font-medium mb-4\">Model Selection Framework</h4>\n                      <div className=\"relative w-full h-64 border rounded-lg overflow-hidden\">\n                        <div className=\"absolute left-0 top-0 w-1/2 h-1/2 bg-blue-100 border-r border-b p-4\">\n                          <p className=\"font-bold\">Data Modality</p>\n                          <p className=\"text-sm\">Structured vs. Unstructured</p>\n                        </div>\n                        <div className=\"absolute right-0 top-0 w-1/2 h-1/2 bg-green-100 border-l border-b p-4\">\n                          <p className=\"font-bold\">Task Type</p>\n                          <p className=\"text-sm\">Classification, Regression, etc.</p>\n                        </div>\n                        <div className=\"absolute left-0 bottom-0 w-1/2 h-1/2 bg-yellow-100 border-r border-t p-4\">\n                          <p className=\"font-bold\">Learning Paradigm</p>\n                          <p className=\"text-sm\">Supervised, Unsupervised, etc.</p>\n                        </div>\n                        <div className=\"absolute right-0 bottom-0 w-1/2 h-1/2 bg-purple-100 border-l border-t p-4\">\n                          <p className=\"font-bold\">Constraints</p>\n                          <p className=\"text-sm\">Resources, Interpretability, etc.</p>\n                        </div>\n                      </div>\n                    </div>\n                  )}\n                  \n                  {activeModule === AI_MODULES.REGULATION && (\n                    <div className=\"mt-6\">\n                      <h4 className=\"text-lg font-medium mb-4\">Federal AI Policy Pillars</h4>\n                      <div className=\"h-64\">\n                        <ResponsiveContainer width=\"100%\" height=\"100%\">\n                          <BarChart \n                            data={[\n                              { name: \"Governance\", value: 100 },\n                              { name: \"Transparency\", value: 100 },\n                              { name: \"Accountability\", value: 100 },\n                              { name: \"Privacy\", value: 100 },\n                              { name: \"Security\", value: 100 },\n                              { name: \"Fairness\", value: 100 }\n                            ]}\n                          >\n                            <CartesianGrid strokeDasharray=\"3 3\" />\n                            <XAxis dataKey=\"name\" />\n                            <YAxis domain={[0, 100]} />\n                            <Tooltip />\n                            <Bar dataKey=\"value\" fill=\"#8884d8\" />\n                          </BarChart>\n                        </ResponsiveContainer>\n                      </div>\n                    </div>\n                  )}\n                </div>\n              )}\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default Dashboard;"],"mappings":"AAAA,MAAO,CAAAA,KAAK,EAAIC,QAAQ,KAAQ,OAAO,CACvC,OAASC,QAAQ,CAAEC,GAAG,CAAEC,KAAK,CAAEC,KAAK,CAAEC,aAAa,CAAEC,OAAO,CAAEC,MAAM,CAAEC,mBAAmB,CAAEC,UAAU,CAAEC,SAAS,CAAEC,cAAc,CAAEC,eAAe,CAAEC,KAAK,KAAQ,UAAU,CAC1K,OAASC,IAAI,CAAEC,WAAW,CAAEC,aAAa,CAAEC,OAAO,CAAEC,UAAU,CAAEC,WAAW,CAAEC,SAAS,CAAEC,QAAQ,KAAQ,cAAc,CAAC,OAAAC,GAAA,IAAAC,IAAA,CAAAC,IAAA,IAAAC,KAAA,CAAAC,QAAA,IAAAC,SAAA,yBAEvH,KAAM,CAAAC,UAAU,CAAG,CACjBC,OAAO,CAAE,YAAY,CACrBC,UAAU,CAAE,eAAe,CAC3BC,cAAc,CAAE,gBAAgB,CAChCC,IAAI,CAAE,SACR,CAAC,CAED,KAAM,CAAAC,eAAe,CAAG,CACtB,CAACL,UAAU,CAACC,OAAO,EAAG,CACpBK,KAAK,CAAE,kBAAkB,CACzBC,WAAW,CAAE,2HAA2H,CACxIC,UAAU,CAAE,wBAAwB,CACpCC,UAAU,CAAE,kCACd,CAAC,CACD,CAACT,UAAU,CAACE,UAAU,EAAG,CACvBI,KAAK,CAAE,wBAAwB,CAC/BC,WAAW,CAAE,2GAA2G,CACxHC,UAAU,CAAE,8BAA8B,CAC1CC,UAAU,CAAE,qCACd,CAAC,CACD,CAACT,UAAU,CAACG,cAAc,EAAG,CAC3BG,KAAK,CAAE,gBAAgB,CACvBC,WAAW,CAAE,sIAAsI,CACnJC,UAAU,CAAE,iCAAiC,CAC7CC,UAAU,CAAE,yCACd,CAAC,CACD,CAACT,UAAU,CAACI,IAAI,EAAG,CACjBE,KAAK,CAAE,oBAAoB,CAC3BC,WAAW,CAAE,oGAAoG,CACjHC,UAAU,CAAE,mBAAmB,CAC/BC,UAAU,CAAE,sCACd,CACF,CAAC,CAED;AACA,KAAM,CAAAC,aAAa,CAAG,CACpB,CAACV,UAAU,CAACC,OAAO,EAAG,CACpB,CACEK,KAAK,CAAE,eAAe,CACtBK,KAAK,CAAE,CACL,kQAAkQ,CAClQ,6PAA6P,CAC7P,qOAAqO,CACrO,6OAA6O,CAEjP,CAAC,CACD,CACEL,KAAK,CAAE,uBAAuB,CAC9BK,KAAK,CAAE,CACL,yUAAyU,CACzU,qUAAqU,CACrU,sSAAsS,CACtS,4SAA4S,CAEhT,CAAC,CACD,CACEL,KAAK,CAAE,mBAAmB,CAC1BK,KAAK,CAAE,CACL,+XAA+X,CAC/X,wWAAwW,CACxW,+WAA+W,CAC/W,8ZAA8Z,CAEla,CAAC,CACD,CACEL,KAAK,CAAE,aAAa,CACpBK,KAAK,CAAE,CACL,8dAA8d,CAC9d,kZAAkZ,CAClZ,gcAAgc,CAChc,0VAA0V,CAE9V,CAAC,CACF,CACD,CAACX,UAAU,CAACE,UAAU,EAAG,CACvB,CACEI,KAAK,CAAE,6BAA6B,CACpCK,KAAK,CAAE,CACL,8WAA8W,CAC9W,0YAA0Y,CAC1Y,6ZAA6Z,CAEja,CAAC,CACD,CACEL,KAAK,CAAE,6BAA6B,CACpCK,KAAK,CAAE,CACL,wdAAwd,CACxd,4eAA4e,CAC5e,ogBAAogB,CAExgB,CAAC,CACD,CACEL,KAAK,CAAE,kCAAkC,CACzCK,KAAK,CAAE,CACL,4gBAA4gB,CAC5gB,+eAA+e,CAC/e,+hBAA+hB,CAEniB,CAAC,CACD,CACEL,KAAK,CAAE,+BAA+B,CACtCK,KAAK,CAAE,CACL,4gBAA4gB,CAC5gB,yfAAyf,CACzf,ykBAAykB,CAE7kB,CAAC,CACD,CACEL,KAAK,CAAE,kCAAkC,CACzCK,KAAK,CAAE,CACL,oEAAoE,CACpE,qFAAqF,CACrF,2FAA2F,CAE/F,CAAC,CACD,CACEL,KAAK,CAAE,oCAAoC,CAC3CK,KAAK,CAAE,CACL,kFAAkF,CAClF,0FAA0F,CAC1F,uFAAuF,CAE3F,CAAC,CACD,CACEL,KAAK,CAAE,uBAAuB,CAC9BK,KAAK,CAAE,CACL,kFAAkF,CAClF,8FAA8F,CAC9F,6EAA6E,CAEjF,CAAC,CACD,CACEL,KAAK,CAAE,uCAAuC,CAC9CK,KAAK,CAAE,CACL,iGAAiG,CACjG,8EAA8E,CAC9E,yEAAyE,CAE7E,CAAC,CACD,CACEL,KAAK,CAAE,wCAAwC,CAC/CK,KAAK,CAAE,CACL,4FAA4F,CAC5F,qFAAqF,CACrF,2FAA2F,CAE/F,CAAC,CACF,CACD,CAACX,UAAU,CAACG,cAAc,EAAG,CAC3B,CACEG,KAAK,CAAE,iBAAiB,CACxBK,KAAK,CAAE,CACL,ihBAAihB,CACjhB,4gBAA4gB,CAC5gB,igBAAigB,CACjgB,6fAA6f,CAC7f,ghBAAghB,CAEphB,CAAC,CACD,CACEL,KAAK,CAAE,oBAAoB,CAC3BK,KAAK,CAAE,CACL,mlBAAmlB,CACnlB,slBAAslB,CACtlB,0gBAA0gB,CAC1gB,+fAA+f,CAC/f,mgBAAmgB,CAEvgB,CAAC,CACD,CACEL,KAAK,CAAE,+BAA+B,CACtCK,KAAK,CAAE,CACL,iGAAiG,CACjG,wFAAwF,CACxF,wFAAwF,CACxF,gFAAgF,CAChF,2FAA2F,CAE/F,CAAC,CACD,CACEL,KAAK,CAAE,gBAAgB,CACvBK,KAAK,CAAE,CACL,yFAAyF,CACzF,6EAA6E,CAC7E,2EAA2E,CAC3E,yFAAyF,CACzF,wFAAwF,CAE5F,CAAC,CACD,CACEL,KAAK,CAAE,0BAA0B,CACjCK,KAAK,CAAE,CACL,8EAA8E,CAC9E,qFAAqF,CACrF,4EAA4E,CAC5E,2EAA2E,CAC3E,qEAAqE,CAEzE,CAAC,CACF,CACD,CAACX,UAAU,CAACI,IAAI,EAAG,CACjB,CACEE,KAAK,CAAE,yBAAyB,CAChCK,KAAK,CAAE,CACL,udAAud,CACvd,yfAAyf,CACzf,6eAA6e,CAC7e,6dAA6d,CAC7d,gdAAgd,CAEpd,CAAC,CACD,CACEL,KAAK,CAAE,4CAA4C,CACnDK,KAAK,CAAE,CACL,ihBAAihB,CACjhB,8hBAA8hB,CAC9hB,meAAme,CACne,odAAod,CACpd,+cAA+c,CAEnd,CAAC,CACD,CACEL,KAAK,CAAE,wBAAwB,CAC/BK,KAAK,CAAE,CACL,mkBAAmkB,CACnkB,6hBAA6hB,CAC7hB,kfAAkf,CAClf,mdAAmd,CACnd,odAAod,CAExd,CAAC,CACD,CACEL,KAAK,CAAE,qCAAqC,CAC5CK,KAAK,CAAE,CACL,6jBAA6jB,CAC7jB,0dAA0d,CAC1d,qcAAqc,CACrc,icAAic,CACjc,ufAAuf,CAE3f,CAAC,CAEL,CAAC,CAED;AACA,KAAM,CAAAC,cAAc,CAAG,CACrB,CAACZ,UAAU,CAACC,OAAO,EAAG,CACpB,CACEY,QAAQ,CAAE,0DAA0D,CACpEC,OAAO,CAAE,CAAC,cAAc,CAAE,WAAW,CAAE,YAAY,CAAE,kBAAkB,CAAE,YAAY,CAAE,kBAAkB,CAAC,CAC1GC,QAAQ,CAAE,eACZ,CAAC,CACD,CACEF,QAAQ,CAAE,2DAA2D,CACrEC,OAAO,CAAE,CAAC,gBAAgB,CAAE,YAAY,CAAE,YAAY,CAAE,mBAAmB,CAAE,gBAAgB,CAAE,6BAA6B,CAAC,CAC7HC,QAAQ,CAAE,uBACZ,CAAC,CACD,CACEF,QAAQ,CAAE,+DAA+D,CACzEC,OAAO,CAAE,CAAC,qBAAqB,CAAE,uBAAuB,CAAE,0BAA0B,CAAE,wBAAwB,CAAE,mBAAmB,CAAC,CACpIC,QAAQ,CAAE,mBACZ,CAAC,CACD,CACEF,QAAQ,CAAE,wEAAwE,CAClFC,OAAO,CAAE,CAAC,oCAAoC,CAAE,6CAA6C,CAAE,qDAAqD,CAAC,CACrJC,QAAQ,CAAE,aACZ,CAAC,CACD,CACEF,QAAQ,CAAE,gEAAgE,CAC1EC,OAAO,CAAE,CAAC,6BAA6B,CAAE,wBAAwB,CAAE,iCAAiC,CAAE,yCAAyC,CAAC,CAChJC,QAAQ,CAAE,aACZ,CAAC,CACF,CACD,CAACf,UAAU,CAACE,UAAU,EAAG,CACvB,CACEW,QAAQ,CAAE,kEAAkE,CAC5EC,OAAO,CAAE,CAAC,uBAAuB,CAAE,sBAAsB,CAAE,oBAAoB,CAAE,gBAAgB,CAAC,CAClGC,QAAQ,CAAE,6BAA6B,CACvCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,mFAAmF,CAC7FC,OAAO,CAAE,CAAC,kCAAkC,CAAE,mCAAmC,CAAE,aAAa,CAAE,IAAI,CAAC,CACvGC,QAAQ,CAAE,6BAA6B,CACvCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,yDAAyD,CACnEC,OAAO,CAAE,CAAC,qCAAqC,CAAE,0BAA0B,CAAE,kBAAkB,CAAE,mBAAmB,CAAC,CACrHC,QAAQ,CAAE,6BAA6B,CACvCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,4EAA4E,CACtFC,OAAO,CAAE,CAAC,sBAAsB,CAAE,gCAAgC,CAAE,yCAAyC,CAAE,wBAAwB,CAAC,CACxIC,QAAQ,CAAE,6BAA6B,CACvCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,8EAA8E,CACxFC,OAAO,CAAE,CAAC,+BAA+B,CAAE,oBAAoB,CAAE,oBAAoB,CAAE,eAAe,CAAC,CACvGC,QAAQ,CAAE,kCAAkC,CAC5CC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,uEAAuE,CACjFC,OAAO,CAAE,CAAC,oCAAoC,CAAE,yBAAyB,CAAE,6CAA6C,CAAE,6BAA6B,CAAC,CACxJC,QAAQ,CAAE,+BAA+B,CACzCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,qEAAqE,CAC/EC,OAAO,CAAE,CAAC,6BAA6B,CAAE,yBAAyB,CAAE,yBAAyB,CAAE,oBAAoB,CAAC,CACpHC,QAAQ,CAAE,kCAAkC,CAC5CC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,yEAAyE,CACnFC,OAAO,CAAE,CAAC,0BAA0B,CAAE,8BAA8B,CAAE,oBAAoB,CAAE,eAAe,CAAC,CAC5GC,QAAQ,CAAE,oCAAoC,CAC9CC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,yEAAyE,CACnFC,OAAO,CAAE,CAAC,+BAA+B,CAAE,yBAAyB,CAAE,iBAAiB,CAAE,0BAA0B,CAAC,CACpHC,QAAQ,CAAE,uBAAuB,CACjCC,MAAM,CAAE,CACV,CAAC,CACF,CACD,CAAChB,UAAU,CAACG,cAAc,EAAG,CAC3B,CACEU,QAAQ,CAAE,2EAA2E,CACrFC,OAAO,CAAE,CAAC,8BAA8B,CAAE,oBAAoB,CAAE,mBAAmB,CAAE,eAAe,CAAC,CACrGC,QAAQ,CAAE,iBAAiB,CAC3BC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,yEAAyE,CACnFC,OAAO,CAAE,CAAC,2BAA2B,CAAE,0BAA0B,CAAE,0BAA0B,CAAE,WAAW,CAAC,CAC3GC,QAAQ,CAAE,iBAAiB,CAC3BC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,6DAA6D,CACvEC,OAAO,CAAE,CAAC,sBAAsB,CAAE,kBAAkB,CAAE,qBAAqB,CAAE,yBAAyB,CAAC,CACvGC,QAAQ,CAAE,oBAAoB,CAC9BC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,qFAAqF,CAC/FC,OAAO,CAAE,CAAC,0BAA0B,CAAE,oBAAoB,CAAE,mBAAmB,CAAE,oBAAoB,CAAC,CACtGC,QAAQ,CAAE,oBAAoB,CAC9BC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,2EAA2E,CACrFC,OAAO,CAAE,CAAC,kCAAkC,CAAE,uBAAuB,CAAE,qBAAqB,CAAE,6BAA6B,CAAC,CAC5HC,QAAQ,CAAE,+BAA+B,CACzCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,+DAA+D,CACzEC,OAAO,CAAE,CAAC,sBAAsB,CAAE,2BAA2B,CAAE,oBAAoB,CAAE,sBAAsB,CAAC,CAC5GC,QAAQ,CAAE,gBAAgB,CAC1BC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,6DAA6D,CACvEC,OAAO,CAAE,CAAC,yBAAyB,CAAE,iBAAiB,CAAE,iBAAiB,CAAE,YAAY,CAAC,CACxFC,QAAQ,CAAE,gBAAgB,CAC1BC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,qEAAqE,CAC/EC,OAAO,CAAE,CAAC,4BAA4B,CAAE,iBAAiB,CAAE,eAAe,CAAE,YAAY,CAAC,CACzFC,QAAQ,CAAE,0BAA0B,CACpCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,uDAAuD,CACjEC,OAAO,CAAE,CAAC,4BAA4B,CAAE,qBAAqB,CAAE,mBAAmB,CAAE,eAAe,CAAC,CACpGC,QAAQ,CAAE,0BAA0B,CACpCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,8DAA8D,CACxEC,OAAO,CAAE,CAAC,+BAA+B,CAAE,kBAAkB,CAAE,kBAAkB,CAAE,eAAe,CAAC,CACnGC,QAAQ,CAAE,0BAA0B,CACpCC,MAAM,CAAE,CACV,CAAC,CACF,CACD,CAAChB,UAAU,CAACI,IAAI,EAAG,CACjB,CACES,QAAQ,CAAE,0EAA0E,CACpFC,OAAO,CAAE,CAAC,sBAAsB,CAAE,mBAAmB,CAAE,iBAAiB,CAAE,aAAa,CAAC,CACxFC,QAAQ,CAAE,yBAAyB,CACnCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,6FAA6F,CACvGC,OAAO,CAAE,CAAC,+BAA+B,CAAE,oBAAoB,CAAE,oBAAoB,CAAE,eAAe,CAAC,CACvGC,QAAQ,CAAE,yBAAyB,CACnCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,4EAA4E,CACtFC,OAAO,CAAE,CAAC,+BAA+B,CAAE,oBAAoB,CAAE,oBAAoB,CAAE,eAAe,CAAC,CACvGC,QAAQ,CAAE,yBAAyB,CACnCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,gFAAgF,CAC1FC,OAAO,CAAE,CAAC,kBAAkB,CAAE,cAAc,CAAE,iBAAiB,CAAE,uBAAuB,CAAC,CACzFC,QAAQ,CAAE,4CAA4C,CACtDC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,iEAAiE,CAC3EC,OAAO,CAAE,CAAC,0BAA0B,CAAE,kBAAkB,CAAE,6BAA6B,CAAE,eAAe,CAAC,CACzGC,QAAQ,CAAE,4CAA4C,CACtDC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,8CAA8C,CACxDC,OAAO,CAAE,CAAC,wBAAwB,CAAE,sBAAsB,CAAE,yBAAyB,CAAE,cAAc,CAAC,CACtGC,QAAQ,CAAE,4CAA4C,CACtDC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,2EAA2E,CACrFC,OAAO,CAAE,CAAC,kCAAkC,CAAE,uBAAuB,CAAE,uBAAuB,CAAE,kBAAkB,CAAC,CACnHC,QAAQ,CAAE,wBAAwB,CAClCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,gEAAgE,CAC1EC,OAAO,CAAE,CAAC,sBAAsB,CAAE,mBAAmB,CAAE,oBAAoB,CAAE,sBAAsB,CAAC,CACpGC,QAAQ,CAAE,wBAAwB,CAClCC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,qFAAqF,CAC/FC,OAAO,CAAE,CAAC,uBAAuB,CAAE,oBAAoB,CAAE,gBAAgB,CAAE,cAAc,CAAC,CAC1FC,QAAQ,CAAE,qCAAqC,CAC/CC,MAAM,CAAE,CACV,CAAC,CACD,CACEH,QAAQ,CAAE,gEAAgE,CAC1EC,OAAO,CAAE,CAAC,mCAAmC,CAAE,wBAAwB,CAAE,wBAAwB,CAAE,mBAAmB,CAAC,CACvHC,QAAQ,CAAE,qCAAqC,CAC/CC,MAAM,CAAE,CACV,CAAC,CAEL,CAAC,CAED;AACA,KAAM,CAAAC,qBAAqB,CAAG,CAC5B,iDAAiD,CAAE,CACjDC,KAAK,CAAE,sDAAsD,CAC7DC,SAAS,CAAE,0KACb,CAAC,CACD,6CAA6C,CAAE,CAC7CD,KAAK,CAAE,6DAA6D,CACpEC,SAAS,CAAE,uIACb,CAAC,CACD,8CAA8C,CAAE,CAC9CD,KAAK,CAAE,uCAAuC,CAC9CC,SAAS,CAAE,qHACb,CAAC,CACD,+CAA+C,CAAE,CAC/CD,KAAK,CAAE,gDAAgD,CACvDC,SAAS,CAAE,wGACb,CAAC,CACD,kDAAkD,CAAE,CAClDD,KAAK,CAAE,mDAAmD,CAC1DC,SAAS,CAAE,4GACb,CAAC,CACD,+CAA+C,CAAE,CAC/CD,KAAK,CAAE,0CAA0C,CACjDC,SAAS,CAAE,0FACb,CAAC,CACD,sDAAsD,CAAE,CACtDD,KAAK,CAAE,+CAA+C,CACtDC,SAAS,CAAE,2FACb,CACF,CAAC,CAED;AACA,KAAM,CAAAC,oBAAoB,CAAGA,CAACC,OAAO,CAAEC,MAAM,GAAK,CAChD,GAAI,CAACD,OAAO,EAAI,CAACA,OAAO,CAACC,MAAM,CAAC,EAAIC,MAAM,CAACC,IAAI,CAACH,OAAO,CAACC,MAAM,CAAC,CAAC,CAACG,MAAM,GAAK,CAAC,CAAE,CAC7E,MAAO,CAAEC,KAAK,CAAE,CAAC,CAAEC,QAAQ,CAAE,CAAC,CAAEC,UAAU,CAAE,CAAE,CAAC,CACjD,CAEA,KAAM,CAAAC,SAAS,CAAGjB,cAAc,CAACU,MAAM,CAAC,CACxC,GAAI,CAAAI,KAAK,CAAG,CAAC,CACb,GAAI,CAAAC,QAAQ,CAAG,CAAC,CAEhBJ,MAAM,CAACO,OAAO,CAACT,OAAO,CAACC,MAAM,CAAC,CAAC,CAACS,OAAO,CAACC,IAAA,EAAsB,IAArB,CAACC,MAAM,CAAEC,MAAM,CAAC,CAAAF,IAAA,CACvD,KAAM,CAAAnB,QAAQ,CAAGgB,SAAS,CAACM,QAAQ,CAACF,MAAM,CAAC,CAAC,CAC5C,KAAM,CAAAG,WAAW,CAAGvB,QAAQ,CAACC,OAAO,CAACuB,OAAO,CAACH,MAAM,CAAC,CACpD,KAAM,CAAAlB,MAAM,CAAGH,QAAQ,CAACG,MAAM,EAAI,CAAC,CAEnC;AACA,KAAM,CAAAsB,WAAW,CAAGzB,QAAQ,CAACC,OAAO,CAACW,MAAM,CAAGW,WAAW,CACzDV,KAAK,EAAIY,WAAW,CAAGtB,MAAM,CAC7BW,QAAQ,EAAId,QAAQ,CAACC,OAAO,CAACW,MAAM,CAAGT,MAAM,CAC9C,CAAC,CAAC,CAEF,KAAM,CAAAY,UAAU,CAAGD,QAAQ,CAAG,CAAC,CAAGY,IAAI,CAACC,KAAK,CAAEd,KAAK,CAAGC,QAAQ,CAAI,GAAG,CAAC,CAAG,CAAC,CAE1E,MAAO,CAAED,KAAK,CAAEC,QAAQ,CAAEC,UAAW,CAAC,CACxC,CAAC,CAED,KAAM,CAAAa,kBAAkB,CAAIb,UAAU,EAAK,CACzC,GAAIA,UAAU,EAAI,EAAE,CAAE,MAAO,CAAEc,KAAK,CAAE,iBAAiB,CAAEC,KAAK,CAAE,SAAS,CAAEC,IAAI,cAAEjD,IAAA,CAACR,WAAW,EAAC0D,IAAI,CAAE,EAAG,CAAE,CAAE,CAAC,CAC5G,GAAIjB,UAAU,EAAI,EAAE,CAAE,MAAO,CAAEc,KAAK,CAAE,qBAAqB,CAAEC,KAAK,CAAE,SAAS,CAAEC,IAAI,cAAEjD,IAAA,CAACP,aAAa,EAACyD,IAAI,CAAE,EAAG,CAAE,CAAE,CAAC,CAClH,MAAO,CAAEH,KAAK,CAAE,gBAAgB,CAAEC,KAAK,CAAE,SAAS,CAAEC,IAAI,cAAEjD,IAAA,CAACN,OAAO,EAACwD,IAAI,CAAE,EAAG,CAAE,CAAE,CAAC,CACnF,CAAC,CAED,KAAM,CAAAC,sBAAsB,CAAIzB,OAAO,EAAK,CAC1C,GAAI,CAACA,OAAO,EAAI,CAACA,OAAO,CAACrB,UAAU,CAACC,OAAO,CAAC,CAAE,MAAO,KAAI,CAEzD,KAAM,CAAA8C,cAAc,CAAG1B,OAAO,CAACrB,UAAU,CAACC,OAAO,CAAC,CAClD,GAAIsB,MAAM,CAACC,IAAI,CAACuB,cAAc,CAAC,CAACtB,MAAM,CAAG,CAAC,CAAE,MAAO,KAAI,CAEvD,KAAM,CAAAuB,QAAQ,CAAGD,cAAc,CAAC,CAAC,CAAC,CAAE;AACpC,KAAM,CAAAE,QAAQ,CAAGF,cAAc,CAAC,CAAC,CAAC,CAAE;AACpC,KAAM,CAAAG,YAAY,CAAGH,cAAc,CAAC,CAAC,CAAC,CAAE;AAExC,KAAM,CAAAI,GAAG,CAAG,GAAGH,QAAQ,IAAIC,QAAQ,IAAIC,YAAY,EAAE,CACrD,MAAO,CAAAjC,qBAAqB,CAACkC,GAAG,CAAC,EAAI,CACnCjC,KAAK,CAAE,wBAAwB,CAC/BC,SAAS,CAAE,oHACb,CAAC,CACH,CAAC,CAED;AACA,KAAM,CAAAiC,iBAAiB,CAAGA,CAAC/B,OAAO,CAAEC,MAAM,GAAK,CAC7C,GAAI,CAACD,OAAO,EAAI,CAACA,OAAO,CAACC,MAAM,CAAC,EAAIC,MAAM,CAACC,IAAI,CAACH,OAAO,CAACC,MAAM,CAAC,CAAC,CAACG,MAAM,GAAK,CAAC,CAAE,CAC7E,MAAO,EAAE,CACX,CAEA,KAAM,CAAAI,SAAS,CAAGjB,cAAc,CAACU,MAAM,CAAC,CACxC,KAAM,CAAA+B,UAAU,CAAG,CAAC,CAAC,CAErB;AACAxB,SAAS,CAACE,OAAO,CAACuB,CAAC,EAAI,CACrB,GAAI,CAACD,UAAU,CAACC,CAAC,CAACvC,QAAQ,CAAC,CAAE,CAC3BsC,UAAU,CAACC,CAAC,CAACvC,QAAQ,CAAC,CAAG,CACvBA,QAAQ,CAAEuC,CAAC,CAACvC,QAAQ,CACpBW,KAAK,CAAE,CAAC,CACRC,QAAQ,CAAE,CAAC,CACXC,UAAU,CAAE,CAAC,CACbC,SAAS,CAAE,CAAC,CACZ0B,iBAAiB,CAAE,CACrB,CAAC,CACH,CACAF,UAAU,CAACC,CAAC,CAACvC,QAAQ,CAAC,CAACc,SAAS,EAAI,CAAC,CACvC,CAAC,CAAC,CAEF;AACAN,MAAM,CAACO,OAAO,CAACT,OAAO,CAACC,MAAM,CAAC,CAAC,CAACS,OAAO,CAACyB,KAAA,EAAsB,IAArB,CAACvB,MAAM,CAAEC,MAAM,CAAC,CAAAsB,KAAA,CACvD,KAAM,CAAA3C,QAAQ,CAAGgB,SAAS,CAACM,QAAQ,CAACF,MAAM,CAAC,CAAC,CAC5C,KAAM,CAAAlB,QAAQ,CAAGF,QAAQ,CAACE,QAAQ,CAClC,KAAM,CAAAqB,WAAW,CAAGvB,QAAQ,CAACC,OAAO,CAACuB,OAAO,CAACH,MAAM,CAAC,CACpD,KAAM,CAAAlB,MAAM,CAAGH,QAAQ,CAACG,MAAM,EAAI,CAAC,CAEnC;AACA,KAAM,CAAAsB,WAAW,CAAGzB,QAAQ,CAACC,OAAO,CAACW,MAAM,CAAGW,WAAW,CAEzDiB,UAAU,CAACtC,QAAQ,CAAC,CAACW,KAAK,EAAIY,WAAW,CAAGtB,MAAM,CAClDqC,UAAU,CAACtC,QAAQ,CAAC,CAACY,QAAQ,EAAId,QAAQ,CAACC,OAAO,CAACW,MAAM,CAAGT,MAAM,CACjEqC,UAAU,CAACtC,QAAQ,CAAC,CAACwC,iBAAiB,EAAI,CAAC,CAC7C,CAAC,CAAC,CAEF;AACAhC,MAAM,CAACkC,MAAM,CAACJ,UAAU,CAAC,CAACtB,OAAO,CAAChB,QAAQ,EAAI,CAC5CA,QAAQ,CAACa,UAAU,CAAGb,QAAQ,CAACY,QAAQ,CAAG,CAAC,CACvCY,IAAI,CAACC,KAAK,CAAEzB,QAAQ,CAACW,KAAK,CAAGX,QAAQ,CAACY,QAAQ,CAAI,GAAG,CAAC,CACtD,CAAC,CACP,CAAC,CAAC,CAEF,MAAO,CAAAJ,MAAM,CAACkC,MAAM,CAACJ,UAAU,CAAC,CAClC,CAAC,CAED,KAAM,CAAAK,SAAS,CAAGA,CAAA,GAAM,CACtB,KAAM,CAACC,YAAY,CAAEC,eAAe,CAAC,CAAGxF,QAAQ,CAAC4B,UAAU,CAACC,OAAO,CAAC,CACpE,KAAM,CAAC4D,UAAU,CAAEC,aAAa,CAAC,CAAG1F,QAAQ,CAAC,eAAe,CAAC,CAAE;AAC/D,KAAM,CAACiD,OAAO,CAAE0C,UAAU,CAAC,CAAG3F,QAAQ,CAAC,CACrC,CAAC4B,UAAU,CAACC,OAAO,EAAG,CAAC,CAAC,CACxB,CAACD,UAAU,CAACE,UAAU,EAAG,CAAC,CAAC,CAC3B,CAACF,UAAU,CAACG,cAAc,EAAG,CAAC,CAAC,CAC/B,CAACH,UAAU,CAACI,IAAI,EAAG,CAAC,CACtB,CAAC,CAAC,CACF,KAAM,CAAC4D,WAAW,CAAEC,cAAc,CAAC,CAAG7F,QAAQ,CAAC,KAAK,CAAC,CAErD,KAAM,CAAA8F,YAAY,CAAGA,CAACC,aAAa,CAAEjC,MAAM,GAAK,CAC9C6B,UAAU,CAACK,IAAI,GAAK,CAClB,GAAGA,IAAI,CACP,CAACT,YAAY,EAAG,CACd,GAAGS,IAAI,CAACT,YAAY,CAAC,CACrB,CAACQ,aAAa,EAAGjC,MACnB,CACF,CAAC,CAAC,CAAC,CACL,CAAC,CAED,KAAM,CAAAmC,kBAAkB,CAAI/C,MAAM,EAAK,CACrCsC,eAAe,CAACtC,MAAM,CAAC,CACvB2C,cAAc,CAAC,KAAK,CAAC,CACvB,CAAC,CAED,KAAM,CAAAK,mBAAmB,CAAGA,CAAA,GAAM,CAChCL,cAAc,CAAC,IAAI,CAAC,CACtB,CAAC,CAED,KAAM,CAAAM,kBAAkB,CAAGA,CAAA,GAAM,CAC/BR,UAAU,CAACK,IAAI,GAAK,CAClB,GAAGA,IAAI,CACP,CAACT,YAAY,EAAG,CAAC,CACnB,CAAC,CAAC,CAAC,CACHM,cAAc,CAAC,KAAK,CAAC,CACvB,CAAC,CAED,KAAM,CAAAO,WAAW,CAAGpD,oBAAoB,CAACC,OAAO,CAAEsC,YAAY,CAAC,CAC/D,KAAM,CAAAc,cAAc,CAAGrB,iBAAiB,CAAC/B,OAAO,CAAEsC,YAAY,CAAC,CAC/D,KAAM,CAAAe,eAAe,CAAGjC,kBAAkB,CAAC+B,WAAW,CAAC5C,UAAU,CAAC,CAClE,KAAM,CAAA+C,mBAAmB,CAAGhB,YAAY,GAAK3D,UAAU,CAACC,OAAO,CAAG6C,sBAAsB,CAACzB,OAAO,CAAC,CAAG,IAAI,CAExG,mBACExB,KAAA,QAAK+E,SAAS,CAAC,yBAAyB,CAAAC,QAAA,eAEtChF,KAAA,QAAK+E,SAAS,CAAC,0BAA0B,CAAAC,QAAA,eACvClF,IAAA,OAAIiF,SAAS,CAAC,8CAA8C,CAAAC,QAAA,CAAC,yBAAuB,CAAI,CAAC,cACzFlF,IAAA,MAAGiF,SAAS,CAAC,gCAAgC,CAAAC,QAAA,CAAC,sDAAoD,CAAG,CAAC,EACnG,CAAC,cAENlF,IAAA,QAAKiF,SAAS,CAAC,6BAA6B,CAAAC,QAAA,cAC1ChF,KAAA,QAAK+E,SAAS,CAAC,iCAAiC,CAAAC,QAAA,eAE9ClF,IAAA,QAAKiF,SAAS,CAAC,iBAAiB,CAAAC,QAAA,cAC9BhF,KAAA,QAAK+E,SAAS,CAAC,uCAAuC,CAAAC,QAAA,eACpDlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,SAAO,CAAI,CAAC,cACrDlF,IAAA,OAAIiF,SAAS,CAAC,WAAW,CAAAC,QAAA,CACtBtD,MAAM,CAACO,OAAO,CAACzB,eAAe,CAAC,CAACyE,GAAG,CAACC,KAAA,MAAC,CAAC5B,GAAG,CAAE6B,KAAK,CAAC,CAAAD,KAAA,oBAChDpF,IAAA,OAEEsF,OAAO,CAAEA,CAAA,GAAMZ,kBAAkB,CAAClB,GAAG,CAAE,CACvCyB,SAAS,CAAE,iCAAiCjB,YAAY,GAAKR,GAAG,CAAG,aAAa,CAAG,mBAAmB,EAAG,CAAA0B,QAAA,cAEzGhF,KAAA,QAAK+E,SAAS,CAAC,mBAAmB,CAAAC,QAAA,EAC/B1B,GAAG,GAAKnD,UAAU,CAACC,OAAO,eAAIN,IAAA,CAACH,SAAS,EAACqD,IAAI,CAAE,EAAG,CAAC+B,SAAS,CAAC,oBAAoB,CAAE,CAAC,CACpFzB,GAAG,GAAKnD,UAAU,CAACE,UAAU,eAAIP,IAAA,CAACF,QAAQ,EAACoD,IAAI,CAAE,EAAG,CAAC+B,SAAS,CAAC,qBAAqB,CAAE,CAAC,CACvFzB,GAAG,GAAKnD,UAAU,CAACG,cAAc,eAAIR,IAAA,CAACR,WAAW,EAAC0D,IAAI,CAAE,EAAG,CAAC+B,SAAS,CAAC,sBAAsB,CAAE,CAAC,CAC/FzB,GAAG,GAAKnD,UAAU,CAACI,IAAI,eAAIT,IAAA,CAACP,aAAa,EAACyD,IAAI,CAAE,EAAG,CAAC+B,SAAS,CAAC,sBAAsB,CAAE,CAAC,cACxFjF,IAAA,SAAAkF,QAAA,CAAOG,KAAK,CAAC1E,KAAK,CAAO,CAAC,EACvB,CAAC,EAVD6C,GAWH,CAAC,EACN,CAAC,CACA,CAAC,cAELxD,IAAA,OAAIiF,SAAS,CAAC,MAAM,CAAE,CAAC,cAEvB/E,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,kBAAkB,CAAAC,QAAA,CAAC,iBAAe,CAAI,CAAC,CACpDtD,MAAM,CAACO,OAAO,CAACzB,eAAe,CAAC,CAACyE,GAAG,CAACI,KAAA,EAAkB,IAAjB,CAAC/B,GAAG,CAAE6B,KAAK,CAAC,CAAAE,KAAA,CAChD,KAAM,CAAAC,iBAAiB,CAAG5D,MAAM,CAACC,IAAI,CAACH,OAAO,CAAC8B,GAAG,CAAC,CAAC,CAAC1B,MAAM,CAC1D,KAAM,CAAA2D,cAAc,CAAGxE,cAAc,CAACuC,GAAG,CAAC,CAAC1B,MAAM,CACjD,KAAM,CAAA4D,kBAAkB,CAAG9C,IAAI,CAACC,KAAK,CAAE2C,iBAAiB,CAAGC,cAAc,CAAI,GAAG,CAAC,CAEjF,mBACEvF,KAAA,QAAe+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eAC7BhF,KAAA,QAAK+E,SAAS,CAAC,mCAAmC,CAAAC,QAAA,eAChDlF,IAAA,SAAMiF,SAAS,CAAC,SAAS,CAAAC,QAAA,CAAEG,KAAK,CAAC1E,KAAK,CAAO,CAAC,cAC9CT,KAAA,SAAM+E,SAAS,CAAC,SAAS,CAAAC,QAAA,EAAEM,iBAAiB,CAAC,GAAC,CAACC,cAAc,EAAO,CAAC,EAClE,CAAC,cACNzF,IAAA,QAAKiF,SAAS,CAAC,qCAAqC,CAAAC,QAAA,cAClDlF,IAAA,QACEiF,SAAS,CAAC,kBAAkB,CAC5BU,KAAK,CAAE,CACLC,KAAK,CAAE,GAAGF,kBAAkB,GAAG,CAC/BG,eAAe,CAAErC,GAAG,GAAKnD,UAAU,CAACC,OAAO,CAAG,SAAS,CACzCkD,GAAG,GAAKnD,UAAU,CAACE,UAAU,CAAG,SAAS,CACzCiD,GAAG,GAAKnD,UAAU,CAACG,cAAc,CAAG,SAAS,CAAG,SAChE,CAAE,CACE,CAAC,CACJ,CAAC,GAfEgD,GAgBL,CAAC,CAEV,CAAC,CAAC,EACC,CAAC,cAENxD,IAAA,QAAKiF,SAAS,CAAC,gCAAgC,CAAAC,QAAA,cAC7ChF,KAAA,QAAK+E,SAAS,CAAC,kBAAkB,CAAAC,QAAA,eAC/BlF,IAAA,CAACT,IAAI,EAAC2D,IAAI,CAAE,EAAG,CAAC+B,SAAS,CAAC,yBAAyB,CAAE,CAAC,cACtDjF,IAAA,MAAGiF,SAAS,CAAC,uBAAuB,CAAAC,QAAA,CAAC,4GAErC,CAAG,CAAC,EACD,CAAC,CACH,CAAC,EACH,CAAC,CACH,CAAC,cAGNlF,IAAA,QAAKiF,SAAS,CAAC,iBAAiB,CAAAC,QAAA,cAC9BhF,KAAA,QAAK+E,SAAS,CAAC,iCAAiC,CAAAC,QAAA,eAC9ChF,KAAA,QAAK+E,SAAS,CAAC,gDAAgD,CAAAC,QAAA,eAC7DlF,IAAA,OAAIiF,SAAS,CAAC,qBAAqB,CAAAC,QAAA,CAAExE,eAAe,CAACsD,YAAY,CAAC,CAACrD,KAAK,CAAK,CAAC,cAC9ET,KAAA,QAAAgF,QAAA,eACElF,IAAA,WACEiF,SAAS,CAAE,QAAQf,UAAU,GAAK,eAAe,CAAG,wBAAwB,CAAG,aAAa,oBAAqB,CACjHoB,OAAO,CAAEA,CAAA,GAAMnB,aAAa,CAAC,eAAe,CAAE,CAAAe,QAAA,CAC/C,eAED,CAAQ,CAAC,cACTlF,IAAA,WACEiF,SAAS,CAAE,GAAGf,UAAU,GAAK,OAAO,CAAG,wBAAwB,CAAG,aAAa,oBAAqB,CACpGoB,OAAO,CAAEA,CAAA,GAAMnB,aAAa,CAAC,OAAO,CAAE,CAAAe,QAAA,CACvC,mBAED,CAAQ,CAAC,EACN,CAAC,EACH,CAAC,cAENhF,KAAA,QAAK+E,SAAS,CAAC,sCAAsC,CAAAC,QAAA,eACnDlF,IAAA,CAACL,UAAU,EAACuD,IAAI,CAAE,EAAG,CAAC+B,SAAS,CAAC,yBAAyB,CAAE,CAAC,cAC5DjF,IAAA,MAAGiF,SAAS,CAAC,SAAS,CAAAC,QAAA,CACnBxE,eAAe,CAACsD,YAAY,CAAC,CAACpD,WAAW,CACzC,CAAC,EACD,CAAC,CAELsD,UAAU,GAAK,eAAe,cAC7BhE,KAAA,QAAK+E,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClBlF,IAAA,OAAIiF,SAAS,CAAC,cAAc,CAAAC,QAAA,CAAExE,eAAe,CAACsD,YAAY,CAAC,CAAClD,UAAU,CAAK,CAAC,CAE3E,CAACuD,WAAW,cACXnE,KAAA,CAAAE,SAAA,EAAA8E,QAAA,EACGjE,cAAc,CAAC+C,YAAY,CAAC,CAACmB,GAAG,CAAC,CAACxB,CAAC,CAAEmC,KAAK,gBACzC5F,KAAA,QAAiB+E,SAAS,CAAC,wCAAwC,CAAAC,QAAA,eACjEhF,KAAA,QAAK+E,SAAS,CAAC,iBAAiB,CAAAC,QAAA,eAC9BhF,KAAA,OAAI+E,SAAS,CAAC,2BAA2B,CAAAC,QAAA,EACtCY,KAAK,CAAG,CAAC,CAAC,IAAE,CAACnC,CAAC,CAACzC,QAAQ,EACtB,CAAC,cACLhB,KAAA,MAAG+E,SAAS,CAAC,uBAAuB,CAAAC,QAAA,EAAC,YACzB,CAACvB,CAAC,CAACvC,QAAQ,EACpB,CAAC,EACD,CAAC,cACNpB,IAAA,QAAKiF,SAAS,CAAC,KAAK,CAAAC,QAAA,cAClBlF,IAAA,QAAKiF,SAAS,CAAC,sDAAsD,CAAAC,QAAA,CAClEvB,CAAC,CAACxC,OAAO,CAACgE,GAAG,CAAC,CAACY,MAAM,CAAEC,QAAQ,gBAC9BhG,IAAA,WAEEiF,SAAS,CAAE,6BAA6BvD,OAAO,CAACsC,YAAY,CAAC,CAAC8B,KAAK,CAAC,GAAKC,MAAM,CAAG,wBAAwB,CAAG,iBAAiB,EAAG,CACjIT,OAAO,CAAEA,CAAA,GAAMf,YAAY,CAACuB,KAAK,CAAEC,MAAM,CAAE,CAAAb,QAAA,CAE1Ca,MAAM,EAJFC,QAKC,CACT,CAAC,CACC,CAAC,CACH,CAAC,GArBEF,KAsBL,CACN,CAAC,cAEF5F,KAAA,QAAK+E,SAAS,CAAC,2BAA2B,CAAAC,QAAA,eACxClF,IAAA,WACEiF,SAAS,CAAC,+DAA+D,CACzEK,OAAO,CAAEV,kBAAmB,CAAAM,QAAA,CAC7B,OAED,CAAQ,CAAC,cACTlF,IAAA,WACEiF,SAAS,CAAC,4DAA4D,CACtEK,OAAO,CAAEX,mBAAoB,CAAAO,QAAA,CAC9B,QAED,CAAQ,CAAC,EACN,CAAC,EACN,CAAC,cAEH;AACAhF,KAAA,QAAAgF,QAAA,eACEhF,KAAA,QAAK+E,SAAS,CAAC,wCAAwC,CAAAC,QAAA,eACrDlF,IAAA,QAAKiF,SAAS,CAAC,yBAAyB,CAAAC,QAAA,cACtClF,IAAA,OAAIiF,SAAS,CAAC,mBAAmB,CAAAC,QAAA,CAAC,oBAAkB,CAAI,CAAC,CACtD,CAAC,cACNhF,KAAA,QAAK+E,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClBhF,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,0BAAwB,CAAI,CAAC,cACtEhF,KAAA,QAAK+E,SAAS,CAAC,wBAAwB,CAAAC,QAAA,eACrClF,IAAA,QAAKiF,SAAS,CAAC,WAAW,CAAAC,QAAA,cACxBlF,IAAA,QAAKiF,SAAS,CAAC,uCAAuC,CAAAC,QAAA,cACpDlF,IAAA,QACEiF,SAAS,CAAC,oBAAoB,CAC9BU,KAAK,CAAE,CACLC,KAAK,CAAE,GAAGf,WAAW,CAAC5C,UAAU,GAAG,CACnC4D,eAAe,CAAEd,eAAe,CAAC/B,KACnC,CAAE,CACE,CAAC,CACJ,CAAC,CACH,CAAC,cACN9C,KAAA,SAAM+E,SAAS,CAAC,gBAAgB,CAAAC,QAAA,EAC7BL,WAAW,CAAC5C,UAAU,CAAC,GAC1B,EAAM,CAAC,EACJ,CAAC,cACN/B,KAAA,QAAK+E,SAAS,CAAC,mBAAmB,CAAAC,QAAA,eAChClF,IAAA,SAAMiF,SAAS,CAAC,MAAM,CAACU,KAAK,CAAE,CAAE3C,KAAK,CAAE+B,eAAe,CAAC/B,KAAM,CAAE,CAAAkC,QAAA,CAC5DH,eAAe,CAAC9B,IAAI,CACjB,CAAC,cACPjD,IAAA,SAAM2F,KAAK,CAAE,CAAE3C,KAAK,CAAE+B,eAAe,CAAC/B,KAAM,CAAE,CAAAkC,QAAA,CAC3CH,eAAe,CAAChC,KAAK,CAClB,CAAC,EACJ,CAAC,EACH,CAAC,CAELiB,YAAY,GAAK3D,UAAU,CAACC,OAAO,eAClCJ,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,oBAAkB,CAAI,CAAC,cAChElF,IAAA,QAAKiF,SAAS,CAAC,MAAM,CAAAC,QAAA,cACnBlF,IAAA,CAACf,mBAAmB,EAAC2G,KAAK,CAAC,MAAM,CAACK,MAAM,CAAC,MAAM,CAAAf,QAAA,CAC5ClB,YAAY,GAAK3D,UAAU,CAACG,cAAc,cACzCN,KAAA,CAAChB,UAAU,EAACgH,WAAW,CAAE,EAAG,CAACC,IAAI,CAAErB,cAAe,CAAAI,QAAA,eAChDlF,IAAA,CAACb,SAAS,GAAE,CAAC,cACba,IAAA,CAACZ,cAAc,EAACgH,OAAO,CAAC,UAAU,CAAE,CAAC,cACrCpG,IAAA,CAACX,eAAe,EAACgH,MAAM,CAAE,CAAC,CAAC,CAAE,GAAG,CAAE,CAAE,CAAC,cACrCrG,IAAA,CAACV,KAAK,EAACgH,IAAI,CAAC,OAAO,CAACF,OAAO,CAAC,YAAY,CAACG,MAAM,CAAC,SAAS,CAACC,IAAI,CAAC,SAAS,CAACC,WAAW,CAAE,GAAI,CAAE,CAAC,cAC7FzG,IAAA,CAACjB,OAAO,EAAC2H,SAAS,CAAGrB,KAAK,EAAK,CAAC,GAAGA,KAAK,GAAG,CAAE,OAAO,CAAE,CAAE,CAAC,EAC/C,CAAC,cAEbnF,KAAA,CAACxB,QAAQ,EAACyH,IAAI,CAAErB,cAAe,CAAAI,QAAA,eAC7BlF,IAAA,CAAClB,aAAa,EAAC6H,eAAe,CAAC,KAAK,CAAE,CAAC,cACvC3G,IAAA,CAACpB,KAAK,EAACwH,OAAO,CAAC,UAAU,CAAE,CAAC,cAC5BpG,IAAA,CAACnB,KAAK,EAACwH,MAAM,CAAE,CAAC,CAAC,CAAE,GAAG,CAAE,CAAE,CAAC,cAC3BrG,IAAA,CAACjB,OAAO,EAAC2H,SAAS,CAAGrB,KAAK,EAAK,CAAC,GAAGA,KAAK,GAAG,CAAE,OAAO,CAAE,CAAE,CAAC,cACzDrF,IAAA,CAAChB,MAAM,GAAE,CAAC,cACVgB,IAAA,CAACrB,GAAG,EAACyH,OAAO,CAAC,YAAY,CAACE,IAAI,CAAC,kBAAkB,CAACE,IAAI,CAAC,SAAS,CAAE,CAAC,EAC3D,CACX,CACkB,CAAC,CACnB,CAAC,EACH,CACN,CAEAxC,YAAY,GAAK3D,UAAU,CAACC,OAAO,EAAI0E,mBAAmB,eACzD9E,KAAA,QAAK+E,SAAS,CAAC,gCAAgC,CAAAC,QAAA,eAC7ClF,IAAA,OAAIiF,SAAS,CAAC,wBAAwB,CAAAC,QAAA,CAAC,mBAAiB,CAAI,CAAC,cAC7DlF,IAAA,MAAGiF,SAAS,CAAC,wCAAwC,CAAAC,QAAA,CAAEF,mBAAmB,CAACzD,KAAK,CAAI,CAAC,cACrFvB,IAAA,MAAGiF,SAAS,CAAC,eAAe,CAAAC,QAAA,CAAEF,mBAAmB,CAACxD,SAAS,CAAI,CAAC,EAC7D,CACN,cAEDtB,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,uBAAqB,CAAI,CAAC,cACnEhF,KAAA,OAAI+E,SAAS,CAAC,WAAW,CAAAC,QAAA,EACtBJ,cAAc,CACZ8B,MAAM,CAACC,GAAG,EAAIA,GAAG,CAAC5E,UAAU,CAAG,EAAE,CAAC,CAClCkD,GAAG,CAAC,CAAC0B,GAAG,CAAEf,KAAK,gBACd5F,KAAA,OAAgB+E,SAAS,CAAC,wBAAwB,CAAAC,QAAA,eAChDlF,IAAA,MAAGiF,SAAS,CAAC,aAAa,CAAAC,QAAA,CAAE2B,GAAG,CAACzF,QAAQ,CAAI,CAAC,cAC7ClB,KAAA,MAAG+E,SAAS,CAAC,uBAAuB,CAAAC,QAAA,EAAC,iBACpB,CAAC2B,GAAG,CAAC5E,UAAU,CAAC,MAAI,CAAC4E,GAAG,CAACjD,iBAAiB,CAAC,GAAC,CAACiD,GAAG,CAAC3E,SAAS,CAAC,qBAC5E,EAAG,CAAC,GAJG4D,KAKL,CACL,CAAC,CACHhB,cAAc,CAAC8B,MAAM,CAACC,GAAG,EAAIA,GAAG,CAAC5E,UAAU,CAAG,EAAE,CAAC,CAACH,MAAM,GAAK,CAAC,eAC7D9B,IAAA,MAAGiF,SAAS,CAAC,uBAAuB,CAAAC,QAAA,CAAC,6CAErC,CAAG,CACJ,EACC,CAAC,EACF,CAAC,EACH,CAAC,EACH,CAAC,cAENlF,IAAA,WACEiF,SAAS,CAAC,iEAAiE,CAC3EK,OAAO,CAAEA,CAAA,GAAMhB,cAAc,CAAC,KAAK,CAAE,CAAAY,QAAA,CACtC,yBAED,CAAQ,CAAC,EACN,CACN,EACE,CAAC,cAEN;AACAhF,KAAA,QAAK+E,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClBlF,IAAA,OAAIiF,SAAS,CAAC,cAAc,CAAAC,QAAA,CAAExE,eAAe,CAACsD,YAAY,CAAC,CAACnD,UAAU,CAAK,CAAC,CAE3EE,aAAa,CAACiD,YAAY,CAAC,CAACmB,GAAG,CAAC,CAAC2B,OAAO,CAAEhB,KAAK,gBAC9C5F,KAAA,QAAiB+E,SAAS,CAAC,wCAAwC,CAAAC,QAAA,eACjEhF,KAAA,QACE+E,SAAS,CAAC,kEAAkE,CAC5EK,OAAO,CAAEA,CAAA,GAAM,CACb,KAAM,CAAAyB,OAAO,CAAGC,QAAQ,CAACC,cAAc,CAAC,WAAWnB,KAAK,EAAE,CAAC,CAC3D,GAAIiB,OAAO,CAAE,CACXA,OAAO,CAACpB,KAAK,CAACuB,OAAO,CAAGH,OAAO,CAACpB,KAAK,CAACuB,OAAO,GAAK,MAAM,CAAG,OAAO,CAAG,MAAM,CAC7E,CACF,CAAE,CAAAhC,QAAA,eAEFlF,IAAA,OAAIiF,SAAS,CAAC,aAAa,CAAAC,QAAA,CAAE4B,OAAO,CAACnG,KAAK,CAAK,CAAC,cAChDX,IAAA,CAACJ,WAAW,GAAE,CAAC,EACZ,CAAC,cACNI,IAAA,QAAKmH,EAAE,CAAE,WAAWrB,KAAK,EAAG,CAACb,SAAS,CAAC,KAAK,CAAAC,QAAA,cAC1ClF,IAAA,OAAIiF,SAAS,CAAC,WAAW,CAAAC,QAAA,CACtB4B,OAAO,CAAC9F,KAAK,CAACmE,GAAG,CAAC,CAACiC,IAAI,CAAEC,SAAS,gBACjCnH,KAAA,OAAoB+E,SAAS,CAAC,WAAW,CAAAC,QAAA,eACvClF,IAAA,SAAMiF,SAAS,CAAC,oBAAoB,CAAAC,QAAA,CAAC,QAAC,CAAM,CAAC,cAC7ClF,IAAA,SAAAkF,QAAA,CAAOkC,IAAI,CAAO,CAAC,GAFZC,SAGL,CACL,CAAC,CACA,CAAC,CACF,CAAC,GAtBEvB,KAuBL,CACN,CAAC,CAED9B,YAAY,GAAK3D,UAAU,CAACG,cAAc,eACzCN,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,qCAAmC,CAAI,CAAC,cACjFlF,IAAA,QAAKiF,SAAS,CAAC,MAAM,CAAAC,QAAA,cACnBlF,IAAA,CAACf,mBAAmB,EAAC2G,KAAK,CAAC,MAAM,CAACK,MAAM,CAAC,MAAM,CAAAf,QAAA,cAC7ChF,KAAA,CAAChB,UAAU,EACTgH,WAAW,CAAE,EAAG,CAChBC,IAAI,CAAE,CACJ,CAAEmB,IAAI,CAAE,iBAAiB,CAAEC,QAAQ,CAAE,GAAG,CAAElC,KAAK,CAAE,GAAI,CAAC,CACtD,CAAEiC,IAAI,CAAE,oBAAoB,CAAEC,QAAQ,CAAE,GAAG,CAAElC,KAAK,CAAE,GAAI,CAAC,CACzD,CAAEiC,IAAI,CAAE,cAAc,CAAEC,QAAQ,CAAE,GAAG,CAAElC,KAAK,CAAE,GAAI,CAAC,CACnD,CAAEiC,IAAI,CAAE,gBAAgB,CAAEC,QAAQ,CAAE,GAAG,CAAElC,KAAK,CAAE,GAAI,CAAC,CACrD,CAAEiC,IAAI,CAAE,YAAY,CAAEC,QAAQ,CAAE,GAAG,CAAElC,KAAK,CAAE,GAAI,CAAC,CACjD,CAAAH,QAAA,eAEFlF,IAAA,CAACb,SAAS,GAAE,CAAC,cACba,IAAA,CAACZ,cAAc,EAACgH,OAAO,CAAC,MAAM,CAAE,CAAC,cACjCpG,IAAA,CAACX,eAAe,EAACgH,MAAM,CAAE,CAAC,CAAC,CAAE,GAAG,CAAE,CAAE,CAAC,cACrCrG,IAAA,CAACV,KAAK,EAACgH,IAAI,CAAC,WAAW,CAACF,OAAO,CAAC,OAAO,CAACG,MAAM,CAAC,SAAS,CAACC,IAAI,CAAC,SAAS,CAACC,WAAW,CAAE,GAAI,CAAE,CAAC,EAClF,CAAC,CACM,CAAC,CACnB,CAAC,EACH,CACN,CAEAzC,YAAY,GAAK3D,UAAU,CAACI,IAAI,eAC/BP,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,4BAA0B,CAAI,CAAC,cACxElF,IAAA,QAAKiF,SAAS,CAAC,+BAA+B,CAAAC,QAAA,CAC3C,CAAC,KAAK,CAAE,SAAS,CAAE,QAAQ,CAAE,QAAQ,CAAC,CAACC,GAAG,CAAC,CAACqC,IAAI,CAAEC,GAAG,gBACpDzH,IAAA,QAAeiF,SAAS,CAAC,2HAA2H,CAAAC,QAAA,cAClJlF,IAAA,SAAMiF,SAAS,CAAC,yBAAyB,CAAAC,QAAA,CAAEsC,IAAI,CAAO,CAAC,EAD/CC,GAEL,CACN,CAAC,CACC,CAAC,EACH,CACN,CAEAzD,YAAY,GAAK3D,UAAU,CAACC,OAAO,eAClCJ,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,2BAAyB,CAAI,CAAC,cACvEhF,KAAA,QAAK+E,SAAS,CAAC,wDAAwD,CAAAC,QAAA,eACrEhF,KAAA,QAAK+E,SAAS,CAAC,qEAAqE,CAAAC,QAAA,eAClFlF,IAAA,MAAGiF,SAAS,CAAC,WAAW,CAAAC,QAAA,CAAC,eAAa,CAAG,CAAC,cAC1ClF,IAAA,MAAGiF,SAAS,CAAC,SAAS,CAAAC,QAAA,CAAC,6BAA2B,CAAG,CAAC,EACnD,CAAC,cACNhF,KAAA,QAAK+E,SAAS,CAAC,uEAAuE,CAAAC,QAAA,eACpFlF,IAAA,MAAGiF,SAAS,CAAC,WAAW,CAAAC,QAAA,CAAC,WAAS,CAAG,CAAC,cACtClF,IAAA,MAAGiF,SAAS,CAAC,SAAS,CAAAC,QAAA,CAAC,kCAAgC,CAAG,CAAC,EACxD,CAAC,cACNhF,KAAA,QAAK+E,SAAS,CAAC,0EAA0E,CAAAC,QAAA,eACvFlF,IAAA,MAAGiF,SAAS,CAAC,WAAW,CAAAC,QAAA,CAAC,mBAAiB,CAAG,CAAC,cAC9ClF,IAAA,MAAGiF,SAAS,CAAC,SAAS,CAAAC,QAAA,CAAC,gCAA8B,CAAG,CAAC,EACtD,CAAC,cACNhF,KAAA,QAAK+E,SAAS,CAAC,2EAA2E,CAAAC,QAAA,eACxFlF,IAAA,MAAGiF,SAAS,CAAC,WAAW,CAAAC,QAAA,CAAC,aAAW,CAAG,CAAC,cACxClF,IAAA,MAAGiF,SAAS,CAAC,SAAS,CAAAC,QAAA,CAAC,mCAAiC,CAAG,CAAC,EACzD,CAAC,EACH,CAAC,EACH,CACN,CAEAlB,YAAY,GAAK3D,UAAU,CAACE,UAAU,eACrCL,KAAA,QAAK+E,SAAS,CAAC,MAAM,CAAAC,QAAA,eACnBlF,IAAA,OAAIiF,SAAS,CAAC,0BAA0B,CAAAC,QAAA,CAAC,2BAAyB,CAAI,CAAC,cACvElF,IAAA,QAAKiF,SAAS,CAAC,MAAM,CAAAC,QAAA,cACnBlF,IAAA,CAACf,mBAAmB,EAAC2G,KAAK,CAAC,MAAM,CAACK,MAAM,CAAC,MAAM,CAAAf,QAAA,cAC7ChF,KAAA,CAACxB,QAAQ,EACPyH,IAAI,CAAE,CACJ,CAAEG,IAAI,CAAE,YAAY,CAAEjB,KAAK,CAAE,GAAI,CAAC,CAClC,CAAEiB,IAAI,CAAE,cAAc,CAAEjB,KAAK,CAAE,GAAI,CAAC,CACpC,CAAEiB,IAAI,CAAE,gBAAgB,CAAEjB,KAAK,CAAE,GAAI,CAAC,CACtC,CAAEiB,IAAI,CAAE,SAAS,CAAEjB,KAAK,CAAE,GAAI,CAAC,CAC/B,CAAEiB,IAAI,CAAE,UAAU,CAAEjB,KAAK,CAAE,GAAI,CAAC,CAChC,CAAEiB,IAAI,CAAE,UAAU,CAAEjB,KAAK,CAAE,GAAI,CAAC,CAChC,CAAAH,QAAA,eAEFlF,IAAA,CAAClB,aAAa,EAAC6H,eAAe,CAAC,KAAK,CAAE,CAAC,cACvC3G,IAAA,CAACpB,KAAK,EAACwH,OAAO,CAAC,MAAM,CAAE,CAAC,cACxBpG,IAAA,CAACnB,KAAK,EAACwH,MAAM,CAAE,CAAC,CAAC,CAAE,GAAG,CAAE,CAAE,CAAC,cAC3BrG,IAAA,CAACjB,OAAO,GAAE,CAAC,cACXiB,IAAA,CAACrB,GAAG,EAACyH,OAAO,CAAC,OAAO,CAACI,IAAI,CAAC,SAAS,CAAE,CAAC,EAC9B,CAAC,CACQ,CAAC,CACnB,CAAC,EACH,CACN,EACE,CACN,EACE,CAAC,CACH,CAAC,EACH,CAAC,CACH,CAAC,EACH,CAAC,CAEV,CAAC,CAED,cAAe,CAAAzC,SAAS","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}